[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spreadsheet Crash Course",
    "section": "",
    "text": "Preface\nThis is a holding place for the materials for the Cronkite School’s Howard Center spreadsheet reboot.\nThe sections are:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "Spreadsheet Crash Course",
    "section": "",
    "text": "Reporting with data\nUsing spreadsheets in journalism\nNewsroom math",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "start.html",
    "href": "start.html",
    "title": "Reporting with data",
    "section": "",
    "text": "Data reporting has come to mean many things. One of the best descriptions that fits this course is the moniker, “Empirical Journalism”. For us, that means taking a systematic approach to finding, acquiring, evaluating and analyzing all kinds of data for the purpose of uncovering information that was hidden or otherwise ill-understood by the general public. It will teach you to use documents and data as sources like any other, with flaws and motivations that might thwart or help you report a story.\nThis introductory section gives you some of the basic skills you need to begin thinking about data and digitally stored documents as sources for your stories.\nSome of the skill comes from recognizing opportunities when they arise. The chapters on defining, finding and creating data should get you thinking about the many ways information is stored, and how difficult it might be to wrangle it for your story idea.\nThe section on reading and viewing investigations teaches you how to critically look at stories that attempt to use data, and also to learn from imaginative or effective use of it. There are also sections on the bread and butter of working with data: checking your math-phobia at the door and learning to document your work so that it can be published.",
    "crumbs": [
      "Reporting with data"
    ]
  },
  {
    "objectID": "start-story.html",
    "href": "start-story.html",
    "title": "1  Learn a new way to read",
    "section": "",
    "text": "1.1 Read like a reporter\nTry to approach data or empirical reporting as a reporter first, and a consumer second. The goal is to triangulate how the story was discovered, reported and constructed. You’ll want to think about why this story, told this way, at this time, was considered newsworthy enough to publish when another approach on the same topic might not have been.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-story.html#read-like-a-reporter",
    "href": "start-story.html#read-like-a-reporter",
    "title": "1  Learn a new way to read",
    "section": "",
    "text": "What were the questions?\nIn data journalism, we often start with a tip, or a hypothesis. Sometimes it’s a simple question. Walt Bogdanich of The New York Times is renowned for seeing stories around every corner. Bogdanich has said that the prize-winning story “A Disability Epidemic Among a Railroad’s Retirees” came from a simple question he had when railway workers went on strike over pension benefits – how much were they worth? The story led to an FBI investigation and arrests, along with pension reform at the largest commuter rail in the country. 1\nThe hypothesis for some stories might be more directed. In 2021, the Howard Center for Investigative Journalism at ASU published “Little victims everywhere”, a set of stories on the lack of justice for survivors of child sexual assault on Native American reservations. That story came after previous reporters for the center analyzed data from the Justice Department showing that the FBI dropped most of the cases it investigated, and the Justice Department then only prosecuted about half of the matters referred to it by investigators. The hypothesis was that they were rarely pursued because federal prosecutors – usually focused on immigration, white collar crime and drugs – weren’t as prepared to pursue violent crime in Indian Country.\nWhen studying a data-driven investigation, try to imagine what the reporters were trying to prove or disprove, and what they used to do it. In journalism, we rely on a mixture of quantitative and qualitative methods. It’s not enough to prove the “numbers” or have the statistical evidence. That is just the beginning of the story. We are supposed to ground-truth them with the stories of actual people and places.\n\n\nGo beyond the numbers\nIt’s easy to focus on the numbers or statistics that make up the key findings, or the reason for the story. Some reporters make the mistake of thinking all of the numbers came from the same place – a rarity in most long-form investigations. Instead, the sources have been woven together and are a mix of original research and research done by others. Try to pay attention to any sourcing done in the piece. Sometimes, it will tell you that the analysis was original. Other times it’s more subtle.\nBut don’t just look at the statistics being reported in the story. In many (most?) investigations, some of the key people, places or time elements come directly from a database.\nWhen I was analyzing some housing court data for The New York Times, one fact hit me as I was looking at a timeline of eviction cases: The most cases ever filed in one of the city’s courts happened during a Thanksgiving week one year. It was the kind of detail that could have been compelling in a story if it had been more recent.\nOften, the place that a reporter visits is determined by examples found in data. In this story on rural development funds, all of the examples came from an analysis of the database. Once the data gave us a good lead, we examined press releases and other easy-to-get sources before calling and visiting the recipients or towns.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-story.html#reading-tips",
    "href": "start-story.html#reading-tips",
    "title": "1  Learn a new way to read",
    "section": "1.2 Reading tips",
    "text": "1.2 Reading tips\nYou’ll get better at reading investigations and data-driven work over time, but for now, remember to go beyond the obvious:\n\nWhere might the reporters have found their key examples, and what made them good characters or illustrations of the larger issue? Could they have come from the data?\nWhat do you think came first – a narrative single example that was broadened by data , or a big idea that was illustrated with characters ?\nWhat records were used? Were they public records, leaks, or proprietary data?\nWhat methods did they use? Did they do their own testing, use statistical analysis, or geographic methods? You won’t always know, but look for a methodology section or a description alongside each story.\nHow might you localize or adapt these methods to find your own stories?\nPick out the key findings (usually in the nut graf or in a series of bullets after the opening chapter): are they controvesial? How might they have been derived? What might have been the investigative hypothesis? Have they given critics their due and tried to falsify their own work?\nHow effective is the writing and presentation of the story? What makes it compelling journalism rather than a dry study? How might you have done it differently? Is a video story better told in text, or would a text story have made a good documentary? Are the visual elements well integrated? Does the writing draw you in and keep you reading? Think about structure, story length, entry points and graphics all working together.\nAre you convinced? Are there holes or questions that didn’t get addressed?",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-story.html#analyze-data-for-story-not-study",
    "href": "start-story.html#analyze-data-for-story-not-study",
    "title": "1  Learn a new way to read",
    "section": "1.3 Analyze data for story, not study",
    "text": "1.3 Analyze data for story, not study\nAs journalists we’ll often be using data, social science methods and even interviewing differently than true experts. We’re seeking stories, not studies. Recognizing news in data is one of the hardest skills for less experienced reporters new to data journalism. This list of potential newsworthy data points is adapted from Paul Bradshaw’s “Data Journalism Heist”.\n\n\n\n\nCompare the claims of powerful people and institutions against facts – the classic investigative approach.\nReport on unexpected highs and lows (of change, or of some other characteristic)\nLook for outliers – individual values that buck a trend seen in the rest\nVerify or bust some myths\nFind signs of distress, happiness or dishonesty or any other emotion.\nUncover new or under-reported long-term trends.\nFind data suggesting your area is the same or different than most others of its kind.\n\nBradshaw also did a recent study of data journalism pieces: “Here are the angles journalists use most often to tell the stories in data”, in Online Journalism Blog. I’m not sure I agree, only because he’s looking mainly at visualizations rather than stories, but they’re worth considering.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-story.html#exercises",
    "href": "start-story.html#exercises",
    "title": "1  Learn a new way to read",
    "section": "1.4 Exercises",
    "text": "1.4 Exercises\n\nIf you’re a member of Investigative Reporters and Editors, go to the site and find a recent prize-winning entry (usually text rather than broadcast). Get a copy of the IRE contest entry from the Resources page. Try to match up what the reporters said they did and how they did it with key portions of the story.\nThe next time you find a good data source, try to find a story that references it. If your data is local, you might look for a story that used similar data elsewhere, such as 911 response times or overdose deaths. But many stories use federal datasets that can easily be localized. Look at a description of the dataset and then the story to see how the data might have been used.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-story.html#footnotes",
    "href": "start-story.html#footnotes",
    "title": "1  Learn a new way to read",
    "section": "",
    "text": "Note to self: check this with Walt. It’s how I remember it, but I’m not positive.↩︎",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Learn a new way to read</span>"
    ]
  },
  {
    "objectID": "start-math.html",
    "href": "start-math.html",
    "title": "2  Newsroom math",
    "section": "",
    "text": "2.1 Why numbers?\nUsing averages, percentages and percent change is the bread and butter of data journalism, leading to stories ranging from home price comparisons to school reports and crime trends. It may have been charming at one time for reporters to announce that they didn’t “do” math, but no longer. Instead, it is now an announcement that the reporter can only do some of the job. You will never be able to tackle complicated, in-depth stories without reviewing basic math.\nThe good news is that most of the math and statistics you need in a newsroom isn’t nearly as difficult as high school algebra. You learned it somewhere around the 4th grade. You then had a decade to forget it before deciding you didn’t like math. But mastering this most basic arithmetic again is a requirement in the modern age.\nIn working with typical newsroom math, you will need to learn how to:\nWhile this chapter covers general tips, you can find specific instructions for typical newsroom math in this Appendix A",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-math.html#why-numbers",
    "href": "start-math.html#why-numbers",
    "title": "2  Newsroom math",
    "section": "",
    "text": "Overcome your fear of numbers\nIntegrate numbers into your reporting\nRoutinely compute averages, differences and rates\nSimplify and select the right numbers for your story",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-math.html#overcoming-your-fear-of-math",
    "href": "start-math.html#overcoming-your-fear-of-math",
    "title": "2  Newsroom math",
    "section": "2.2 Overcoming your fear of math",
    "text": "2.2 Overcoming your fear of math\nWhen we learned to read, we got used to the idea that 26 letters in American English could be assembled into units that we understand without thinking – words, sentences, paragraphs and books. We never got the same comfort level with 10 digits, and neither did our audience.\nThink of your own reaction to seeing a page of words. Now imagine it as a page of numbers.\nInstead, picture the number “five”. It’s easy. It might be fingers or it might be a team on a basketball court. But it’s simple to understand.\nNow picture the number 275 million. It’s hard. Unfortunately, 275 billion isn’t much harder, even though it’s magnitudes larger. (A million seconds goes by in about 11 days but you may not have been alive for a billion seconds – about 36 years.)\nThe easiest way to get used to some numbers is to learn ways to cut them down to size by calculating rates, ratios or percentages. In your analysis, keep an eye out for the simplest accurate way to characterize the numbers you want to use. “Characterize” is the important word here – it’s not usually necessary to be overly precise so long as your story doesn’t hinge on a nuanced reading of small differences. (And is anything that depends on that news? It may not be.)\nHere’s one example of putting huge numbers in perspective. Pay attention to what you really can picture - it’s probably the $21 equivalent.\n\nThe Chicago hedge fund billionaire Kenneth C. Griffin, for example, earns about $68.5 million a month after taxes, according to court filings made by his wife in their divorce. He has given a total of $300,000 to groups backing Republican presidential candidates. That is a huge sum on its face, yet is the equivalent of only $21.17 for a typical American household, according to Congressional Budget Office data on after-tax income.  “Buying Power”, Nicholas Confessore, Sarah Cohen and Karen Yourish, The New York Times, October 2015\n\nI had written it a even more simply, but editors found the facts so unbelievable that they wanted give readers a chance to do the math themselves. That’s reasonable, but here’s an even simpler way to say it: “earned nearly $1 billion after taxes…He has given $300,000 to groups backing candidates, the equivalent of a dinner at Olive Garden for the typical American family , based on Congressional Budget Office income data.” (And yes, I checked the price for an Olive Garden meal at the time for four people.)",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-math.html#put-math-in-its-place",
    "href": "start-math.html#put-math-in-its-place",
    "title": "2  Newsroom math",
    "section": "2.3 Put math in its place",
    "text": "2.3 Put math in its place\nFor journalists, numbers – or facts – make up the third leg of a stool supported by human stories or anecdotes , and insightful comment from experts. They serve us in three ways:\n\nAs summaries. Almost by definition, a number counts something, averages something, or otherwise summarizes something. Sometimes, it does a good job, as in the average height of Americans. Sometimes it does a terrible job, as in the average income of Americans. Try to find summaries that accurately characterize the real world.\nAs opinions. Sometimes it’s an opinion derived after years of impartial study. Sometimes it’s an opinion tinged with partisan or selective choices of facts. Use them accordingly.\nAs guesses. Sometimes it’s a good guess, sometimes it’s an off-the-cuff guess. And sometimes it’s a hopeful guess. Even when everything is presumably counted many times, it’s still a (very nearly accurate) guess. Yes, the “audits” of presidential election results in several states in 2021 found a handful of errors – not a meaningful number, but a few just the same.\n\nOnce you find the humanity in your numbers, by cutting them down to size and relegating them to their proper role, you’ll find yourself less fearful. You’ll be able to characterize what you’ve learned rather than numb your readers with every number in your notebook. You may even find that finding facts on your own is fun.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-math.html#going-further",
    "href": "start-math.html#going-further",
    "title": "2  Newsroom math",
    "section": "2.4 Going further",
    "text": "2.4 Going further\n\nTipsheets\n\nSteve Doig’s “Math Crib Sheet”\nAppendix A: Common newsroom math, adapted from drafts of the book Numbers in the Newsroom, by Sarah Cohen.\n\n\n\nReading and viewing\n\n“Avoiding Numeric Novcain: Writing Well with Numbers,” by Chip Scanlan, Poynter.com\nT. Christian Miller’s “Writing the data-driven story”\nA viral Twitter thread:\n\n\n\nWhat happens in your head when you do 27+48?\n\n— Gene Belcher (@Wparks91) June 25, 2019",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-math.html#exercises",
    "href": "start-math.html#exercises",
    "title": "2  Newsroom math",
    "section": "2.5 Exercises",
    "text": "2.5 Exercises\n\nImagine that someone gave you $1 million and you could spend it on anything you want. Write down a list of things that would add up to about that amount. That should be easy. Now, imagine someone gave you $1 billion and you could spend it on whatever you want, but anything left over after a year had to be returned. How would you spend it? (You can give away money, but it can’t be more than 50% of a charity’s annual revenues. So you can’t give 10 $100 million gifts!) See how far you get trying to spend it. A few homes, a few yachts, student loan repayments for all of your friends? You’ve hardly gotten started.\nImagine it is Jan. 1, 2020 and you are tasked with writing the annual weather story, summarizing the high and low points of the previous year. Using this daily summary of temperatures, rain and wind for Phoenix, try to find three interesting facts for your story. If you want to download your own data from NOAA, choose “Local Climatalogical Data,” and keep only the rows that refer to “SOD,” or “Summary of Day”.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Newsroom math</span>"
    ]
  },
  {
    "objectID": "start-data-def.html",
    "href": "start-data-def.html",
    "title": "3  Defining “Data”",
    "section": "",
    "text": "3.1 The birth of a dataset\nIn “The Art of Access”, David Cuillier and Charles N. Davis describe a process of tracking down the life and times of a dataset. Their purpose is to make sure they know how to request it from a government agency. The same idea applies to using data that we acquire elsewhere.\nAs reporters, we usually deal with data that was created in the process of doing something else such as conducting an inspection or paying a parking ticket. These datasets are created in government as part of carrying out their work. They form the basis of much investigative reporting and they are often the subject of public records and FOIA requests. They were born as part of the government doing its job, without any thought given to how it might be used in another way. These are often called “administrative records”.\nAnother type of data might be considered “digital trace” data, which often refers to social media posts, online publications and other items that are born in electronic form and posted publicly for anyone to view and use.\nFinally, there are datasets that are compiled or collected specifically for the purpose of studying something. They might be collected in the form of a survey or a poll, or they might be monitoring systems such as pollution or weather stations. In this instance, the information has intrinsic value AS information.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-def.html#granular-and-aggregated-data",
    "href": "start-data-def.html#granular-and-aggregated-data",
    "title": "3  Defining “Data”",
    "section": "3.2 Granular and aggregated data",
    "text": "3.2 Granular and aggregated data\nOne of the hardest concepts for a lot of new data journalists is the idea of granularity of your data source. There are a lot of ways to think about this: individual items in a list vs. figures in a table; original records vs. compilations; granular data vs. statistics.\nGenerally, an investigative reporter is interested in getting data that is as close as possible to the most granular information that exists, at least on computer files. Here’s an example , which might give you a little intuition about why it’s so important to think this way:\n\nExample: Death certificates\nWhen someone dies in the US, a standard death certificate is filled out by a series of officials - the attending physician, the institution where they died and even the funeral direcor.\n\n\n\ndeath certificate\n\n\nHere is a blank version of the standard US death certificate form – notice the detail and the detailed instructions on how it is supposed to be filled out.\nA good reporter could imagine many stories coming out of these little boxes. Limiting yourself to just to COVID-19-related stories: You could profile the local doctor who signed the most COVID-19-related death certificates in their city, or examine the number of deaths that had COVID as a contributing, but not underlying or immediate, cause of death. Or maybe you would want to map the deaths to find the block in your town most devastated by the virus.\nEarly in the pandemic, Coulter Jones and Jon Kamp of the Wall Street Journal examined the records from one of the few states that makes them public, and concluded that “Coronavirus Deaths were Likely Missed in Michigan, Death Certificates Suggest”\n\nBut you probably can’t do that. The reason is that, in most states, death certificates are not public records and are treated as secrets. 2. Instead, state and local governments provide limited statistics related to the deaths, usually by county, with no detail.\nHere’s an example from Arizona — note that we can only see statistics in the way the data source has decided we want to examine them, without access to the underlying information. There’s no way to look at age and race and gender combined for each county, just the generalized statistics for each category alone.\nHere are some of the typical (not universal) characteristics of granular vs. aggregated data:\n\n\n\n\n\n\n\nGranular\nAggregate\n\n\n\n\nIntended for some purpose other than your work\nIntended to be presented as is to the public\n\n\nMany rows (records), few columns (variables)\nMany columns (variables), few rows (records)\n\n\nRequires a good understanding of the source\nExplanatory notes usually come with the data\n\n\nEasy to cross-reference and compile\nOften impossible to repurpose\n\n\nHas few numeric columns\nMay be almost entirely numerical\n\n\nIs intended for use in a database\nIs intended for use in a spreadsheet\n\n\n\nWe often have to consider the trade-offs. Granular data with the detail we need - especially when it involves personally identifiable information like names and addresses - can take months or years of negotiation over public records requests, even when the law allows it. It’s often much easier to convince an agency to provide summarized or incomplete data. Don’t balk at using it if it works for you. But you lose flexibility and have to live with the statistics compiiled for you if you have to settle..\nFor our purposes, it’s important to remember that we can always create aggregated numbers like the ones shown in the Arizona COVID page out of individual items, but you can never de-aggregate statistics into more granular data like the boxes filled out in death certificates.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-def.html#unit-of-analysis-know-your-nouns",
    "href": "start-data-def.html#unit-of-analysis-know-your-nouns",
    "title": "3  Defining “Data”",
    "section": "3.3 Unit of analysis: Know your nouns",
    "text": "3.3 Unit of analysis: Know your nouns\nThat brings us to one of the most important things you must find out about any data you begin to analyze: What noun describes each row? In statistics, these rows might be called observations or cases. In data science, they’re usually called records. Either way, every row must represent the same thing – a person, a place, a year, a water sample or a school. And you can’t really do anything with it until you figure out what that noun is.\nSometimes the only level you can obtain creates problems. In 2015, we did a story at The New York Times called “More Deportation Follow Minor Crimes, Records Show” . The government had claimed it was only removing hardened criminals from the country, but our analysis of the data suggested that many of them were for minor infractions.\nIn writing the piece, we had to work around a problem in our data: the agency refused to provide us anything that would help us distinguish one individual from another. All we knew was that each row represented one deportation, not a person. Without a column that uniquely identified people – say, name and date of birth, or some scrambled version of an their DHS number – we had no way to even estimate how often people were deported multiple times. If you read the story, you’ll see the very careful wording, except when we had reported out and spoken to people on the ground.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-def.html#further-reading",
    "href": "start-data-def.html#further-reading",
    "title": "3  Defining “Data”",
    "section": "3.4 Further reading",
    "text": "3.4 Further reading\n\n“Basic steps in working with data”, the Data Journalism Handbook, Steve Doig, ASU Professor. He describes in this piece the problem of not knowing exactly how the data was compiled.\n“Counting the Infected” , Rob Gebellof on The Daily, July 8, 2020.\n“Spreadsheet thinking vs. Database thinking”, by Robert Kosara, gets at the idea that looking at individual items is often a “database”, and statistical compilations are often “spreadsheets”.\n“Tidy Data”, in the Journal of Statistical Software (linked here in a pre-print) by Hadley Wickham , is the quintessential article on describing what we think of as “clean” data. For our purposes, much of what he describes as “tidy” comes when we have individual, granular records – not statistical compilations. It’s an academic article, but it has the underlying concepts that we’ll be working with all year.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-def.html#exercises",
    "href": "start-data-def.html#exercises",
    "title": "3  Defining “Data”",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\nGet a copy of a parking ticket from your local government, and try to imagine what a database of those would look like. What would every row represent? What would every column represent? What’s missing that you would expect to find, and what is included that surprises you?\nThe next time you get a government statistical report, scour all of the footnotes to find some explanation of where the data came from. You’ll be surprised how often they are compilations of administrative records - the government version of trace data.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-def.html#footnotes",
    "href": "start-data-def.html#footnotes",
    "title": "3  Defining “Data”",
    "section": "",
    "text": "I flipped the order of these two definitions!↩︎\nSee “Secrecy in Death Records: A call to action”, by Megain Craig and Madeleine Davison, Journal of Civic Information, December 2020↩︎",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Defining \"Data\"</span>"
    ]
  },
  {
    "objectID": "start-data-diary.html",
    "href": "start-data-diary.html",
    "title": "4  Replication and the data diary",
    "section": "",
    "text": "4.1 Replication and the data diary\nThe formal processes used by AP might not work for smaller endeavors, but anyone can put the underlying ideas to work. At the Center for Public Integrity, Talia Buford, now at ProPublica, kept a simple Word document with her questions and code annotated to help her repeat her work. That “data diary” served as a backstop and roadmap for fact-checking.\nYour analysis and the way it’s characterized in publication must be demonstrably accurate. That means understanding exactly what you did, why, where it all is and how it should be communicated to a general audience. If you can’t describe exactly where the data came from, what you did to derive your findings, and where to find it all, it simply shouldn’t be published.\nThink of the data work the same way you think about interview notes or transcripts and any other research for a story. You wouldn’t quote a court case without reading it and probably talking to some of the participants. You’d make sure you know where to find the documents and what people say about them. You will consult those documents during your fact-checking. All data work – even the most short-lived – should be documented in at least the same detail. Ideally, someone reading through your notes would be able to repeat your work and understand what it means.\nYou also don’t want your future self to curse your present self. It is very likely you’ll have to drop the work at some point as other stories become more urgent and return to it months later. You should be able to pick up where you left off after briefly refreshing yourself on your work.\nThere are disagreements among reporters about how much to try to make our work replicable just as scientists do. Matt Waite’s rant on the subject prompted me to write a rebuttal. The right answer is probably somewhere in between.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Replication and the data diary</span>"
    ]
  },
  {
    "objectID": "start-data-diary.html#first-steps-in-documentation",
    "href": "start-data-diary.html#first-steps-in-documentation",
    "title": "4  Replication and the data diary",
    "section": "4.2 First steps in documentation",
    "text": "4.2 First steps in documentation\nAnyone who has taken a hard sciences or computer programming class in school probably had to maintain a lab notebook. Your data diary is the same idea – a running list of sources and steps taken to get to the final answers.\nStart the documentation process before you even open a new dataset. For a quick daily story, you might be able to keep your work in one short document or as a page in a spreadsheet file. For a longer project, you may find it easier to break your documents apart into logical pieces. Most computer languages are self-documenting – they write out the steps taken. A data diary may not be necessary when a programming language is combined with narrative as in Jupyter Notebooks in Python or Quarto / R Markdown documents in R.\nWhether doing it alongside computer code or in a separate document, here are some sections that are worth considering whenever you start a story or project.\n\nData sourcing\n\nThe source of YOUR data, and how you know it’s authentic. Be specific. And don’t pretend you got it from the original source when you found it elsewhere, such as in this textbook or in a Github repository.\nDescribe the original source of the data and how it is collected and released.2\nIn a separate set of notes, reference other stories and studies that use this or similar data. Include interview notes, advice, warnings and findings along with stories that have already been done.\nIdentify alternative sources for this and similar or related datasets or documents.\nSpecifically write down where you have stored all of this and how you have organized your work. You want to make sure you can get back to the latest version easily, and that you have all of the supporting documents you need to check it.\n\n\n\nData documentation and flaws 3\n\nBe sure to include links or copies of any original documentation such as a record layout, data dictionary4 or manual. If there isn’t one, consider making a data dictionary with what you’ve learned.\nDocument the ways you checked the integrity of the data. There are many ways it might be inaccurate. Try to reconcile the number of rows and any totals you can produce to match other reports created by the source, or other reports that have used it. On longer stories, you’ll also check for impossible combinations (10-year-olds with DUIs), missing data, improper importing or exporting of dates, among other things. (We’ll come back to this.)\nRecord any questions (and answers as you get them) about the meaning of fields or the scope of the data.\nDocument decisions you’ve made about the scope or method of your analysis. For example, if you want to look at “serious” crimes, describe how and why you categorized each crime as “serious” or “not serious.” Some of these should be vetted by experts or should be verified by documenting industry standards.\nInclude a list of interviews conducted / questions asked of officials and what they said.\n\n\n\nProcessing notes 5\nSome projects require many steps to get to a dataset that can be analyzed. You may have had to scrape the data, combine it with other sources or fix some entries. Some common elements you should document:\n\nHand-made corrections. Try to list every one, but it’s ok if you describe HOW you did it, such as clustering and hand-entering using OpenRefine. Link to any spreadsheet, document or program you used. Just be sure to always work on a copy of the data.\nGeocoding (affixing geographic coordinates to addresses). Note how many were correct, how many missing, and what you did about it.\nA description of how you got messy data into a tabular form or a form suitable for analysis. For example, you may have had to strip headings or flip a spreadsheet on its head. Make sure to write down how you did that.\n\n\n\nThe good part: Your analysis\n\nEach question you asked of your data, and the steps you took to answer it. If you use programming notebooks, write it out in plain language before or after the query or statements.\nVetting of your answers: who has looked them over, commented on them\nWhy they might be wrong.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Replication and the data diary</span>"
    ]
  },
  {
    "objectID": "start-data-diary.html#examples-of-documentation",
    "href": "start-data-diary.html#examples-of-documentation",
    "title": "4  Replication and the data diary",
    "section": "4.3 Examples of documentation",
    "text": "4.3 Examples of documentation\n\nA published Jupyter notebook for an analysis of FEC enforcement actions from the Los Angeles Times’ data desk. Ben Welsh, the author of that notebook, says that there are previous versions with unpublishable work.\nA 2018 Buzzfeed News repo with start-to-finish documentation of an opioid deaths story.\nOne year, I created a dataset for practice in class that contained information on population changes in Arizona counties. It turned out not to be an awesome exercise, but I created an example data diary to go with it that is more instructive than the data itself.\nData cleaning will come up a lot in the future, but it’s closely intertwined with documenting your work. Here’s an email exchange between me and Craig Silverman, now at ProPublica, about the process I used at The New York Times in reporting and fact-checking. This isn’t the same as a process for replication, but it discusses the kinds of things that should be in it.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Replication and the data diary</span>"
    ]
  },
  {
    "objectID": "start-data-diary.html#footnotes",
    "href": "start-data-diary.html#footnotes",
    "title": "4  Replication and the data diary",
    "section": "",
    "text": "Hoyer is now the manager of the Washington Post’s data team, which allows reporters to use R, Python or even SAS. But they still save and organize their projects so that another person can review and replicate them.↩︎\nIf you want to see a project with a lot of data sources and how they might be documented in your notes, take a look at the New York City housing data sources we considered for a project in 2016.↩︎\nHere is an example from the New York State housing court↩︎\nA data dictionary lists every table and column in the database, along with definitions. It may be very straightfoward but can become quite complex.↩︎\nHere is an example from one very complicated dataset↩︎",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Replication and the data diary</span>"
    ]
  },
  {
    "objectID": "start-hunt.html",
    "href": "start-hunt.html",
    "title": "5  Reporting from the outside-in",
    "section": "",
    "text": "5.1 Level 1: News reports and opinion pieces\nThere are very few people, institutions or topics that have never been touched by another news organization. Whenever you start a story, your first stop will be to see what that coverage looks like, and discern what you can learn from it.\nThere are four goals in your review of news sources:",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#level-1-news-reports-and-opinion-pieces",
    "href": "start-hunt.html#level-1-news-reports-and-opinion-pieces",
    "title": "5  Reporting from the outside-in",
    "section": "",
    "text": "What does YOUR audience already know? In particular, if you have a specific news organization you hope will publish your work either as a freelancer or staff writer, it’s incumbent on you to know – in depth – what it has already published. But you’ll also want to know what has been published or aired in other markets, in competitors’ outlets, or in specialized news organizitaions. It will be hard for you to know what is newsworthy until you have a strong understanding of your idea’s place in the marketplace of news.\nWhat are the terms of art and common search terms related to your subject? You learned a little about this in backgrounding people, but it’s important to know what terms to use in the future. For example, trying to find information on hate crimes, you may learn that one term of art is “bias-motivated crime”.\nWhat are common sources of background information? These may include lawmakers, advocacy groups, academic experts or government oversight bodies. They include both documents and human sources.\nWhat are the simplest ways to get to your story? Is there an ongoing under-covered lawsuit, or a government report that no one has noticed? Is there a place you can go to be at the center of the story? Is there one person who, when profiled, could provide the most human approach to the subject? You’re looking to exploit what others have done and others know, without repeating what other news organizations have already done.\n\n\nNational and local news\nBe sure to check the archives of national news outlets for major stories on your topic. You might have to go to the library to get an efficient look at this, and you might end up finding their stories in local news as short versions. For example it’s relatively difficult to find the original version of Associated Press stories, but it’s easy to find a slew of news stories based on their reporting.\nSome sources of news stories include:\n\nNexis, Proquest in the library. Nexis UNI doesn’t have much in it, but it DOES have transcripts of major television news shows, which can be really helpful.\nGoogle News. It’s hard to search Google news using advanced operators. Instead, start in regular Google, then flip over to Google News once you have a good search. Make sure your query is general enough to pick up variations.\nIndividual news site searches (the most difficult approach). The ones that are most difficult at ASU are Bloomberg and Bloomberg/Business Week and The Washington Post. You can get free subscriptions to the Wall Street Journal and the New York Times through the library.\nIRE story archives, which have the advantage of including only major efforts that have been submitted for prizes. You won’t always get the whole story, but you can get a questionnaire filled out by the authors describing their work and their findings.\n\nSometimes, opinion pieces are more enlightening about a topic than straight news stories because the authors must concisely explain something to an audience and tease out the most controversial elements in very few words. Look also for magazine stories in the more explanatory genres, especially the Atlantic, New Yorker and other elite publications.\n\n\nLocal news\nLook for local news stories in other publications, including those that are NOT in your area.\nYou should do a full search in Google and in any special collections that you can for stories in your area. These probably will not be as in-depth as the national stories, but it will help you understand what might be newsworthy in your area. In other areas, the news stories might suggest sources and issues that have can be localized for your story.\n\nNewsBank at the library includes a lot of smaller news organizations\nIf you’re working at the local level, consider creating a custom Google search, such as Arizona sources for the news organizations in your state.\nI also created a custom google search engine that includes 212 non-profit news sites, which are often not big enough to show up in general Google searches.\n\nMake sure to actually review any of the stories you find that are very good fits for your story. You might find experts, references to documents and studies, leads toward lawsuits, and even hashtags that might come in handy later.\nDon’t worry too much about what they actually say – instead, think about how they can contribute to your own story.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#level-2-expert-and-government-reports",
    "href": "start-hunt.html#level-2-expert-and-government-reports",
    "title": "5  Reporting from the outside-in",
    "section": "5.2 Level 2: Expert and government reports",
    "text": "5.2 Level 2: Expert and government reports\nAlmost any topic you might consider has probably been studied by an academic researcher. Virtually any topic that touches on government policy may have been the subject of testimony, investigative reports from inspectors general or auditors. Here are some common document sources for these reports:\n\nAcademic articles\nBe sure to look in Google Scholar separately from Google to find academic articles that relate to your subject. These are often not publicly available, but you can usually get access through a university library. If the library does not offer access, the authors may have posted a working version of the paper on their university web page.\nYou don’t have to understand the whole article, and you are not really THAT concerned right now with exactly what the researcher did. Instead, look for:\n\nThe review of previous work on the subject. These will usually start circling around the most respected researchers, who will show up in all of the literature reviews. They also give you a sense of what about your topic is well-established fact, and what is more theoretical or still not well understood.\nA review of their methods - here, you are looking for ways the researchers found their data. Sometimes they have agreements with public agencies to look at documents that aren’t public. But a remarkable number of them are collections of news stories or other publicly available data that you can use. Look to see if they have made their data public somewhere.\n\nWhen you have read enough, you may want to call one of the researchers. Some are willing to help on a story they care about - others just want to be quoted. Be sure to tell them that you are still doing background on the topic, but that their work has been helpful and you want their advice. Don’t waste their time - be sure to read through their work, even if you don’t understand all of it, before you call. Most academic articles have a lead author identified at the beginning and provide the name of the researcher to contact .\n\n\nGovernment reports\nThe federal government funds many research reports on issues of public policy, and make those reports available for free. Some agencies have quite a bit of research, such as the Justice Department’s Office of Justice Programs, or the Environmental Protection Administration’s research area.\nThese reports are often summaries of statistical programs or otherwise relatively dull reports. But they point to sources of information and may have statistical evidence you need for your story.\nYou can also look at who has gotten grants from the agency to study issues under its purview.\n\n\nGovernment investigations and testimony\nEvery state has a State Auditor, who usually works for the Legislature. These offices look at the health and accountability of spending programs in the state and in local governments. If there is anything on these sites about your topic, they will usually have a good road map to the records they used and the general health of the program.\nFederal agencies have inspectors general who look for waste, fraud and abuse in federal programs; the Government Accountability Office does reports for members of Congress about issues of concern to lawmakers.\nLook also for testimony at public hearings in Congress and the Legislature.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#level-3-advocacy-groups-and-people",
    "href": "start-hunt.html#level-3-advocacy-groups-and-people",
    "title": "5  Reporting from the outside-in",
    "section": "5.3 Level 3: Advocacy groups and people",
    "text": "5.3 Level 3: Advocacy groups and people\nYou can’t do much with a story until you find compelling people to drive the narrative. Lawsuits are the source of many stories on public policy or issues – be sure to look for them. But it’s often easier to find advocacy groups who can point you to people who have been in touch with your story. You should have come across some of these in your earlier research, and now is the time to look at their reports and then contact them. Don’t worry if you don’t find an advocacy group exactly on target – most are happy to help reporters find the right people for their story if they have any interest in the outcome.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#when-you-just-want-to-find-data-and-documents",
    "href": "start-hunt.html#when-you-just-want-to-find-data-and-documents",
    "title": "5  Reporting from the outside-in",
    "section": "5.4 When you just want to find data and documents",
    "text": "5.4 When you just want to find data and documents\nA big part of data reporting is finding, creating or acquiring records you can use electronically.\nSome sources of readily available data could include:\n\nGovernment agencies and open government sites\nHobbyists and interest groups\nData aggregators and data collectors\nAcademic researchers who might share their data\nMicrodata from surveys and some government programs, such as the Census, Medicare, the General Social Survey and several other standard sites.\nSocial data through API’s from Spotify, Twitter and other services.\nDetails scraped from online data sources that aren’t available in bulk.\n\nThere are also more difficult ways to find data:\n\nPublic records requests\nWhistleblower leaks\nHome made databases created from documents, and free text or image document collections.\nResponses to a survey that you conduct yourself.\nYour own testing on issues such as water quality or soil contamination.\n\nWhen you start on a project, you’ll usually rely on experts and advocates to lead you to a lot of the possible data sources. But you can also use these strategies to troll for interesting datasets that might make for good stories or practice.\nListen to any caveats and warnings. You may decide that they’re not important, but you don’t want to be blindsided by them in the end. And be sure to ask what they would do if they were you – often, people who have expertise in data have story or project ideas that they can’t get funded or approved, and would be happy for someone else to do them.\nWhen you search using Google, try to use the advanced commands to more precisely hit your target. This tipsheet goes through all of the Google advanced search operators. It changes a lot.\n\nGovernment agency sites\nTry to guess what government agencies – state, local and federal – have an interest in your topic. Browse through their websites to find “Publications” or “Data and research”, or any searchable database. You’ll often find downloadable data there. Once you learn more, you can also evaluate how hard it will be to scrape the data you want. Don’t limit yourself to the jurisdications you care about. If one city or state has a good dataset, there is a strong chance that your local government will have the same thing.\nLook at federal agency sites to find a least common denominator database – they are usually compiled from more detailed state or local reports.\nEven if you can’t find the database, you might be able to find the name of a datset that is maintained internally in audits, footnotes of reports, or IT initiatives.\nOnce you know a good agency to search, use advanced Google searches for filetype:csv or filetype:xlsx, and limit the site to an agency or city site to bring up datasets that they are letting users download.\n\n\nNews reports\nOne of the most useful sources to find the names of databases and their original sources is news reports that relied on the data, or refers to a data source quoted by experts. It doesn’t matter if you’re looking at your own area or others – most places have the same kinds of information collected and stories are similar across geographic areas.\nYou should get good at using all of the resources as precisely as you can. That means getting very familiar with advanced searching in Google, and using LexisNexis and other news databases provided by the ASU library. These offer much more targeted searching than the usual Google search, and will result in much more on-point stories. When you find a good story, consider logging it in a spreadsheet or in doc, and identify:\n\nWho wrote it and when\nWhat government sources of data are explicitly mentioned.\nWhat analysis of that data was done by the news outlet, or what research it depended on.\nAny terms of art that seem to be used around your topic. For example, hate crimes are more frequently referred to as “bias” crimes in many articles – searching for “hate” might not surface them.\n\n\nIRE.org tipsheets\nAnother source for information on news stories that used data reporting is IRE, which has two ways to search for more details: the ire.org tip sheets and story archive. Log into IRE.org and choose the tipsheets to look for guides from other reporters; choose the story database to look for stories on your general topic and then click into the form that the reporters filled out that go through their sources. You’ll often find a pair of them – a story, and a tip sheet – that were done by the same person the same year.\n(The database library is currently undergoing some review, so a lot of the data listed there could be out of date. But it might also point you to standard sources for data.)\n\n\n\nAcademic articles\nMake sure to do a Google Scholar search for your topic. You will often find one or two researchers who have delved into your subject or a single source. This is often a great shortcut. For example, in the News 21 example, a search of hate crimes in Google Scholar identified an article called “Documenting Hate Crimes in the United States: Some consideration on data sources,” from APA PsycNet. Although this was specifically about sexual orientation and gender diversity, it cataloged the different ways that scholars try to document bias crimes. Once Devine settled on the crime victimization survey, another Google scholar search surfaced an expert on the survey who wrote about how it had changed over the years. He turned out to be the former chief of the Justice Department section that ran the survey, and was one of the project’s best sources. Another source led her to the book, “Statistics for Criminology and Criminal Justice.” One of the authors of that book also provided advice.\nAnother value of this approach is that it will help you find the technical jargon for the topic you’re studying. It’s often very difficult to do literature searches without knowing that term.\n\n\nThink tanks / interest groups\nTry to find some interest groups that care a lot about your topic on all sides. They often have websites with recent research on your topic and might have experts you can consult. Take their advice cautiously because they often have a point to prove and are unabashed about twisting data to make their point. However, you can often use their raw data to draw your own conclusions. Some news organizations frown on this, so be sure to be transparent about who they are and what they’ve done.\nAnother good way to use interest groups and think tanks is to get initial versions of public records from them while you wait for your own requests to be processed. At The Washington Post, we used an old version of a weapons trace database for a year while we fought the government for our own; we also used a copy of Agriculture subsidies acquired by the Environmental Working Group while we were waiting for our own public records requests to be completed.\nSometimes, gathering the Tweets from advocates can provide a rich dataset, and it’s relatively easy to do. For example, I once used the Twitter posts from the Police Misconduct project out of the Cato Institute to get a list of all of the stories they’d compiled on the topic.\n\n\nData collectors\nSeveral sites are trying to make businesses out of collected and maintaining databases. Others make available data that they have collected in the past.\nBe sure to look at the original source for any data you find there. You wouldn’t say a news article came from Google News or Lexis, and you wouldn’t say a dataset came from Google Data Search. If it’s not documented at all, you might have to contact the owner for more detail.\nBe careful of most of these. They’re often old, undocumented and poorly vetted. But they will give you a sense of what you might be able to get from a more reliable source, or give you ideas for your own data collection effort.\n*data.world** wants to be the Facebook or Instagram of data. It has both private and public accounts, and users upload data they want to share. This means it’s as varied as the people who are in it.\nIf your newsroom is an AP member, you might have access to its data.world feed, which contains its curated and documented data that local newsrooms can use for their own stories. Some reporters also use data.world to store their public records. Some government agencies are posting their data directly to data.world. But in other cases, they’re undocumented hobbyists.\nVet these the same way you would Google results.\nJournalists’ sites You can often find individual journalists or journalism organizations in various sharing sites, including Github (which doesn’t show up in default Google searches), data.world and other versioning. Look through their sites to see what they have collected – it’s there to share. Fivethirtyeight, ProPublica and the Los Angeles Times have particularly active data archives.\nGoogle data search is, well, the Google of data. In general, data search has limited sources and is more and more frequently logging data sets that are posted by state and local government sources.\nIt makes no attempt to curate the search, though, so be cautious when you find something.\nOne use for the dataset search is to see what other cities and counties have voluntarily released. When you see that, it often means your local or state government might have similar data you can request.\nFor example, searching for police shootings brings up a dataset released by the Orlando Police Department, which contains far more detail than the same dataset released by Phoenix in 2018:\n\n\n\norlando pd\n\n\nBe sure to look for different terms meaning the same thing. For example, searching “use of force” brings you to completely different sets of data than “police shootings”.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#vetting-data-provenance",
    "href": "start-hunt.html#vetting-data-provenance",
    "title": "5  Reporting from the outside-in",
    "section": "5.5 Vetting data provenance",
    "text": "5.5 Vetting data provenance\nBefore you even open a dataset, you should know how your dataset was collected, who it originally came from and how current it is. A future chapter will go through many of the ways reporters check data they’ve found for completeness, mistakes or other problems.\nAt first blush, look for anything that precludes using the data because you can’t identify who is responsible for it or how it was collected. This is the same basic vetting you’d do on any source you hope to use.\nLook for:\n\nThe original source. If you are getting it from a secondary source, look to see how hard it will be to get from original. If it’s from a secondary source, how reliable is it? Are you going to be comfortable crediting them for the data? If you can’t identify where or how the data was collected, you probably can’t use it.\nHow others have used it and what criticisms were made of that use.\nThe timeliness of the data. Anything more than two or three years old will be effectively useless for a news article. If it’s old, you should have a plan for how it will be updated.\nData definitions, data dictionaries or record layouts. These are maps to the underlying data, and those definitions can prove difficult to understand.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-hunt.html#an-example-news21-hate-in-america",
    "href": "start-hunt.html#an-example-news21-hate-in-america",
    "title": "5  Reporting from the outside-in",
    "section": "5.6 An example: News21 “Hate in America”",
    "text": "5.6 An example: News21 “Hate in America”\n\n\n\n\nIn 2018, News 21 – the multi-university investigative reporting fellowship hosted by ASU’s Cronkite School of Journalism – chose “Hate in America” as its topic for the year. It was a risk because others had been reporting on the subject for more than a year, making it more difficult for News 21 to break new ground. It was also difficult because it became clear quite quickly that no one had documented every case of hate crimes or hate-driven incidents in the U.S.\n\nData News 21 used\nThat meant that the team had to find some creative way to quantify the problem. Some of the sources they used included:\n\nRaw data from the National Crime Victimization Survey, an annual survey of crime victims that asks whether hate was an element of the crime. Reporters Catherine Devine and Allie Bice could have used data from a report produced by the Justice Department, but instead analyzed the raw data in a new way to show that about twice as many incidents may have been motivated by hate than previously acknowledged. That analysis was thoroughly vetted by experts in the survey, in hate crimes, and in criminology. It also created a structure around the entire package and provided a newsy lead to the overview story\nA database created by a team of reporters who monitored two weeks’ of social media activity from users associated with white nationalists, new-Nazis and other far-right groups on sites including Twitter, Facebook, Gab and VK. It enabled Kia Gardener to write:\n\n\nNews 21 monitored the daily social media activity of various far-right users, including white nationalists and neo-Nazis, from June 10 to June 24. Those tracked had more than 3 million followers combined. Reporters recorded and compiled more than 2,500 posts on popular platforms, such as Twitter and Facebook, and emerging social media platforms, including Gab and VK.\n\n\nAbout half the posts were directed at specific demographics or communities, from black Americans and Latinos to Jewish people and LGBTQ members….\n\n\n– Social Media: Where voices of hate find a place to preach, News 21, August 2018\n\n\nFederal prosecutions of hate crimes under the various federal statutes. Reporter Lenny Martinez scraped all of the Justice Department’s hate crime-related press releases to find cases the government bragged about. Those cases were supplemented by a list of cases extracted from Westlaw federal case database. The team logged each case in a Google sheet to show what kinds of incidents were pursued by federal prosecutors, and where.\nProPublica’s “Documenting Hate” project, which, with the Southern Poverty Law Center, tried to compile as many stories as they could about hate incidents. ProPublica’s database was a tip sheet, not a quantification. But it served one key goal of any data source: a source reporters could consult when seeking specific types of examples in specific locations.\nThe FBI Uniform Crime Report’s Hate Crime series. They quickly learned that the data is seriously flawed because of non-response from local police departments and a squishy definition of what should be included. Another flaw was that others, including ProPublica, had thoroughly reported on those flaws and the trends in the data, meaning it failed the test of newsworthiness.\n\n\n\nData the team didn’t use\nThere were also sources that the team considered but didn’t pursue, sometimes because of the difficulty and sometimes because they were less useful to the project than expected:\n\nThe Justice Department’s U.S. attorney case management system, which provided details on cases that the government chose not to pursue along with those they did. (A subsequent analysis showed that the vast majority of these cases were rejected by prosecutors, but vetting the analysis proved too difficult in the time available.)\nDatabases of graffiti maintained by local police departments. This would have required public records requests to each department for records that usually aren’t clearly public. The team also contacted Google and other companies that publish street level images to see if it would be possible to isolate the hate symbols. Companies declined release images that their users had flagged as offensive.\nHistorical questions from the Roper Center for Public Opinion Research and the General Social Survey that might have shed light on attitudes about race and religion over time. These proved to be difficult to match up over the years and didn’t really provide much insight.\n\nThese are just some of the ways the News 21 team looked far and wide for any sources that could be methodically used to document their stories. As with any project of this type, the search often failed but along the way the whole team learned more and more about the topic and got to know experts in a way they wouldn’t have if they were just seeking quotes.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reporting from the outside-in</span>"
    ]
  },
  {
    "objectID": "start-build-own.html",
    "href": "start-build-own.html",
    "title": "6  Build your own database",
    "section": "",
    "text": "6.1 The evolution of a home-made database\nThe day in December 2015 that a San Bernadino couple killed 14 people, The New York Times published a short story called “How Often Do Mass Shootings Occur? On Average, Every Day, Records Show”.\nThat daily story spurred the Times to embark on a project to document each mass shooting in America for a year. Five months later, it published this story:\nHere is how Sharon LaFraniere, Daniela Porat and Agustin Armendariz described the results of their work about 10 paragraphs into the story. (I suggest you also read the lede on your own - it’s an exquisite example of framing a lede anecdote with detail and context.)\nNotice how the authors weave the details that were chronicled in their database with the data points. Now, try to imagine how their dataset might have been organized to allow for such a rich description of the phenomenon.\nThe database, built by Armendariz, and mostly reported by Porat, was designed to anticipate this writing phase:\nWhat didn’t they do?\nThey didn’t bother to standardize names and addresses into their pieces – they had no interest in counting how many “Smith”s were in the database, and didn’t care how often they occurred a Main Street.\nIn other contexts, these fields might be important, but they were only required for filtering and sorting, not for counting. There was no reason to make it more difficult to fill out the database than necessary.\nThey also didn’t try to publish the full dataset. That’s an important consideration, especially if the data you are collecting contains sensitive or potentially erroneous information. Getting it to that level of accuracy might have added several months to the project, and probably would not have served readers any better. (The bare bones list of cases, with a few exceptions, was already available and updated elsewhere.)",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-build-own.html#the-evolution-of-a-home-made-database",
    "href": "start-build-own.html#the-evolution-of-a-home-made-database",
    "title": "6  Build your own database",
    "section": "",
    "text": "Seeking deeper insight into the phenomenon, The New York Times identified and analyzed these 358 shootings with four or more casualties, drawing on two databases assembled from news reports and citizen contributors, and then verifying details with law enforcement agencies.\nOnly a small handful were high-profile mass shootings like those in South Carolina and Oregon. The rest are a pencil sketch of everyday America at its most violent.\nThey chronicle how easily lives are shattered when a firearm is readily available — in a waistband, a glove compartment, a mailbox or garbage can that serves as a gang’s gun locker. They document the mayhem spawned by the most banal of offenses: a push in a bar, a Facebook taunt, the wrong choice of music at a house party. They tally scores of unfortunates in the wrong place at the wrong time: an 11-month-old clinging to his mother’s hip, shot as she prepared to load him into a car; a 77-year-old church deacon, killed by a stray bullet while watching television on his couch.\nThe shootings took place everywhere, but mostly outdoors: at neighborhood barbecues, family reunions, music festivals, basketball tournaments, movie theaters, housing project courtyards, Sweet 16 parties, public parks. Where motives could be gleaned, roughly half involved or suggested crime or gang activity. Arguments that spun out of control accounted for most other shootings, followed by acts of domestic violence.\nThe typical victim was a man between 18 and 30, but more than 1 in 10 were 17 or younger. Less is known about those who pulled the triggers because nearly half of the cases remain unsolved. But of those arrested or identified as suspects, the average age was 27.\nMost of the shootings occurred in economically downtrodden neighborhoods. These shootings, by and large, are not a middle-class phenomenon.\nThe divide is racial as well. Among the cases examined by The Times were 39 domestic violence shootings, and they largely involved white attackers and victims. So did many of the high-profile massacres, including a wild shootout between Texas biker gangs that left nine people dead and 18 wounded.\nOver all, though, nearly three-fourths of victims and suspected assailants whose race could be identified were black. Some experts suggest that helps explain why the drumbeat of dead and wounded does not inspire more outrage.\n\n\n\n\nThe database was split into two separate tables – one that detailed the 358 events and another that detailed the 1,592 victims.\nIt included links to original FOIA requests and documentation they’d need for fact-checking.\nSome columns were categories or items that would be summarized – the ages and ethnicity of the victims, the severity of the injury, and whether it was solved. But much of the data included was detailed descriptions that could be searched using sophisticated filters. Still others were tagged with one-word descriptions that allowed the reporters to pluck just the right examples for just the right part of the story, using words like “suspected gang”, “child”, or “party”. Over time, these tags were reviewed and revised, which is common on small databases like this.\nFact-checking and information for publication was included in the database. For example, the database logged photos, interview and contact notes, and specific entries for name spelling and fact checks. That way the reporters could focus on what was NOT ready for publication, rather than review things they’d already checked.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-build-own.html#when-to-build-your-own-database",
    "href": "start-build-own.html#when-to-build-your-own-database",
    "title": "6  Build your own database",
    "section": "6.2 When to build your own database",
    "text": "6.2 When to build your own database\nThere are a few common reasons to design and build your own data for stories:\n\nThere is a long-running story that is periodically updated with new documents or events that you want to track.\nOne reporter created a spreadsheet to log each event related to Jack Kevorkian, a doctor who became famous for helping people commmit suicide. His list made it easy for him to write a story every time another person died, because he had the full list of people and circumstances and knew what he’d already fact-checked.\nMy first data-driven set of stories came from following the actions of George Steinbrenner, the former principle owner of the New York Yankees, whose family owned a failing shipbuilding company in Tampa in the early 1990s. After I pressed the “sort” button, I discovered that each time he helped the company gain new Navy contracts by lending it money, he demanded repayment as soon as the contract was signed, sending it back into a downward spiral.\nYou are getting information from disparate sources and you need an easy way to search them, arrange them chronologically, and keep track of what you need to verify. Examples include reviewing court cases across jurisdictions or compiling death records from many medical examiners’ officers. This would also work for tracking your own FOIA requests. You’ve read about this in Michael Berens’ story of a serial killer in Illinois.\nYou want to fill in details for every item on a list, like the mass shootings story above. This is quite common – you might have a list of opioid overdose deaths from the medical examiner, but you want to fill out the details of this case. At USA Today, Anthony DeBarros did this after 9/11 to tell the story of every person killed in the World Trade Center, including where they were when the planes hit.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-build-own.html#tools-for-building-databases",
    "href": "start-build-own.html#tools-for-building-databases",
    "title": "6  Build your own database",
    "section": "6.3 Tools for building databases",
    "text": "6.3 Tools for building databases\nThe simplest tool for a one-table database is just Google Sheets or Excel. In both Google and Microsoft 365, it’s possible to create a data entry form that will feed into a form, so you can make it a little more structured than just a free-form spreadsheet. But when it gets a little more complicated or you want more control over the data types and choices, you might choose to use a different product.\nAirtable is one option (ASU has an enterprise account, which will kick in when you create an account with your school email address). More recently, Microsoft created “Lists” to your 365 account, and Google added “Tables” to your Google account. Airtable and Tables are quite limited in the free edition – so limited that you may find it doesn’t meet your needs. But even if you can’t use it for your full dataset, it might be useful as a sandbox for you to test different ways to set up your dataset.\nThese products let you set up related tables, such as the events events and people tables used in the Times story, and create tags or other structured items for you spreadsheet. They’re also good for working in teams.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-build-own.html#how-to-start",
    "href": "start-build-own.html#how-to-start",
    "title": "6  Build your own database",
    "section": "6.4 How to start",
    "text": "6.4 How to start\nWork with everyone who might use the dataset before you start to set out goals. Think about the full range of issues that might come up. Most importantly, how are you going to get the information and how long will it take? Is it just a list of things in chronological order or to provide a quick overview of your reporting? Or are you trying to count specific types of events, such as police shootings by race or gender or the lawyer who has had the most disciplinary actions taken?\nThe difference is whether you are primarily using your dataset for sorting and filtering versus grouping and counting by category.\nYou should also assume that you won’t be able to get all of the information you’d hoped, and that real life doesn’t often fit into neat rectangular boxes. So it’s fine to put in some aspirational columns in case you can get the details, but be sure to stay realistic. If it takes too long to fill out a row in your database, you won’t do it.\nHere are some other considerations:\n\nTry to find an interest group or academic researcher who has already tried to tally the information you’re collecting. They may have good structures that you can adapt to your project. If you can’t, try to find a standard that you want to measure your results against – was a policy followed or not, or was a case solved or not? These are the key statistics that will identify the newsworthiness of your results.\nCarefully define your “universe”. In the case of the Washington Post’s Pulitzer Prize-winning “Fatal Flaws” series on deadly police shootings, the reporters chose to focus only on deaths that were the result of gun discharges in the line of duty. That means they aren’t able to talk about all of the people killed by police, nor all of the people killed in custody, because some happen off hours and others are strangulations or other causes of death. In other cases, you may choose to FOIA the top 50 cities or counties and ignore all the rest. It’s ok to limit your universe. Just be sure that your entire team knows and agrees to the definitions and the limits that places on the results.\nWhat is your unit of analysis, or the noun you use to describe a row in your database? Do you want to count events, people, cases, years, or something else? If so, you should have one and only one row for each of those things, which may mean splitting your work inot more than one data frame or table, the way the Times reporters did for people and events.\nBuild your data dictionary before you start filling out the database, and keep adjusting it as you have to adapt to the real world. Make sure to include a detailed data type (eg, a list separated by semicolons, long text, category, number, date….), and list any standardized words or codes you plan to use (“Y” or “N” for yes and no, for example) .\nReduce the number of columns by smartly combining categories into tags, and considering the way you’ll use a field. For example, sorting by street name isn’t usually very useful (especially when you can filter for it), so there may be no reason to split the street number, name, etc. into different columns. If you enter names in a standard format (eg, Last, First Middle Suffix), then they’re easy to split later on but can be kept in one column and still be sorted. In other words, consider whether you want to be able to sort, filter or count entries. Each of them requires a different level of standardization.\nAnticipate errors. One of the more common problems in creating your own dataset is that the whole purpose of it is to sort or arrange it by date, so you have to enter dates properly. But we rarely do get the exact date for every item in the list. There are several strategies for this, such as entering year, month and day in different columns; or entering an approximate date, and flagging it as “approximate” in a separate field (my preference).\nBuild in fact-checking. If nothing else, be sure to include the source of the information in the row, and provide a way to get back to the original quickly. For example, if you are typing in events from a court case, enter a link to the case folder in one field, and the page number of the item you’re entering in another. If I’m publishing anything from the dataset, I include columns for name checks, fact checks and even whether the narrative has been copy edited.\nHow many columns do you really want? On a spreadsheet, things can bet pretty unwieldy pretty fast. Try to avoid having more than about 15 columns, and try to define them so that most are filled out.\n\nThis is an example of a spreadsheet created to log the first 100 days of the Obama administration. The “subject_tags” column let the reporters enter a variety of categories, which were then normalized when it came time to use them.\n\n\n\n100 days\n\n\nThose tags resulted in it being relatively easy to create graphics like this by filtering for related tags and ordering it by date:\n\n\n\nreversals",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-build-own.html#an-example",
    "href": "start-build-own.html#an-example",
    "title": "6  Build your own database",
    "section": "6.5 An example",
    "text": "6.5 An example\nIn 2013, the New York Times and Frontline collaborated on a story on police-involved domestic violence. Most of the story was a narrative of a single case. But it was important to show that this was not the first time the sheriff in the Florida county was slow to investigate his deputies. Another case several years earlier had the same telltale problems.\nThe Times obtained several key documents in the other case.* You can read a copy of the internal affairs report yourself, but you quickly come away realizing that it’s hard to follow, repetitive and you’re never quite sure what’s happened. Here is the record layout of the table that we built, and a small snippet of what it looks like.\n\n\n\ndata dict\n\n\nAnd here is what a few rows look like. Notice that they are not organized chronologically, but are organized in the order that they were listed in the underlying document. The “sort” button turns it into a chronology.\n\n\n\nsjso-example\n\n\nAnd finally, here is what was written about the case in the final story:\n\nA year before that, Sheriff Shoar’s disciplinary posture had been called into question in a domestic violence case involving a deputy named Halford (Bubba) Harris II.\nTwo supervisors learned of accusations that Mr. Harris had abused his wife. But no investigation was immediately opened, records show.\nOne sergeant did prepare an affidavit documenting the accusations. But he was told by his supervisor to hold it back, so he stuck it under the visor in his squad car, where it remained, even after another officer became aware of further incidents, according to Mr. Harris’s internal affairs file.\nThe case came to a head on Christmas Eve, when his wife fled their house and called the police. Internal affairs officers uncovered other possible acts of domestic violence before his hiring, records show. His wife said that before they married, he had held a knife to her throat and hit her. His ex-wife said he had threatened her with a gun. No charges were filed.\nCol. Todd R. Thompson, the sheriff’s director of law enforcement, recommended that Mr. Harris be fired, saying his actions were “particularly egregious and trouble me deeply.”\n\nWas it necessary to create a spreadsheet logging almost 100 events in this case? No. But we had to go through every document in detail anyway, and this meant we didn’t have to do it over and over again.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Build your own database</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html",
    "href": "start-scrape-nocode.html",
    "title": "7  Scraping without programming",
    "section": "",
    "text": "7.1 Where reporters get data\nReporters can get data from people, using FOIA, asking nicely or by finding a whistleblower to leak it. But we often also get data from publicly published sources, usually on the web.\nThere are three ways to get data from the web:",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html#where-reporters-get-data",
    "href": "start-scrape-nocode.html#where-reporters-get-data",
    "title": "7  Scraping without programming",
    "section": "",
    "text": "Download it, or use an API1. In these cases, the makers of the data have specifically offered it up for your use in a useful format. We’ll cover API’s later, but don’t forget to study the site for a download link or option. If there isn’t one on a government site, you might call the agency and ask that they add one. They might just do it. We’ve been using downloadable data throughout this book.\nFind it on your browser. Often the person making the website delivers structured data to your browser as a convenience. It’s easier for them to make interactive items on their page by using data they’ve already delivered in visualizations and tables. It also reduces the loads on their servers. These are usually in JSON format. You might be able to find it right on your computer. It’s a miracle!\nScrape it. This set of chapters goes over how to scrape content that is delivered in HTML form – a web page. There would be other methods to scrape PDFs, which can be easy or hard.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html#a-json-miracle-walkthrough",
    "href": "start-scrape-nocode.html#a-json-miracle-walkthrough",
    "title": "7  Scraping without programming",
    "section": "7.2 A json miracle walkthrough",
    "text": "7.2 A json miracle walkthrough\nThis walkthrough shows you how to find some json in your browser. Use the Chrome browser for this - Firefox and Safari also have similar features, but they look different.\nHere is a simple page that will show you what the json looks like and how to extract it. This is what a human sees:\n\nThe table of presidents is actually produced using a small javascript program inside the HTML that walks through each item and lists it as a row.\n\nOpen the page in Chrome, then right-click anywhere on the page and choose “Inspect”. It may appear as just two items - the “head” and the “body”. But notice the little arrows - they show you that there is more content underneath. For now, we’ll ignore this, but it will be important later.\nChoose the Network tab, then re-load the page.\n\n\n\n\ninspect network\n\n\nThis shows you everything that the browser is attempting to load into your browser. (You may not see the “favicon” item. I have no idea why it’s showing up on mine - it’s not been requested!)\nYou can ignore most of this. Importantly, the “simple-page.html” is the actual page, and the “simple.json” is the data! Click on the simple.json row, then choose the “Response” tab:\n\n\n\nsimple json\n\n\nThat’s what json looks like - a list of rows within an item called “presidents”, each identified by the name of the column they’ll become.2\n\nRight-click on the simple.json file name, and you’ll see a lot of options. Choose the one that says Copy-&gt;Copy link address.\nGo to a new browser window and search for “json to csv”. This one is one that I often see first.\nPaste your copied link in the tab that says, “Enter URL” and press “Load URL”. You’ll see an option to copy the result as a csv file!\n\n\n\n\njson to csv\n\n\n\nA harder example\nThat was easy! But it’s also trivial. However, this method can often save you from having to page through results of a page. One example is the Maricopa County nightly list of mugshots, which may have several hundred new entries each day. Here’s what today’s looked like on a desktop browser (it looks different on a smaller screen).3:\n\n\n\nmcso list\n\n\nIt looks like you’d have to go through each of the five pages to get all of the names of people who were booked into jail that night, but often a json file contains all of them – they’re just showing you one page at a time.\n\nThis page won’t let you right-click to get the inspector. Instead, on a Mac, press Opt-Cmd-C to open the inspector window. (I think it’s Shft-Ctl-C on Windows, but I’m not sure.)\n\nThis looks like a mess! Don’t worry. Switch to the Network tab, and re-load the page. This time, there are dozens of different things that get loaded on your page, and none of them are obviously json. You have a few strategies to find it.\n\nPress the “Fetch/XHR” tab to see if it shows up there. Use the “Preview” tab to look at what each of them is, and, miracle of miracles, it’s the third one on the list! Even better, it has all 425 entries! (It looks like they’re split into groups of 100, but they really aren’t.)\n\n\n\n\nmiracle 1\n\n\n\nRight-click on the name of the file, and choose Copy-&gt;Copy link, and repeat the process above to convert it to a CSV file.\n\n\n\n\n\n\n\nNote\n\n\n\nIn 2022, the county began limiting the number of results to some random list of 300. It appears that searching for an inmate only checks those first 300 results. (It could have been a coincidence that there were exactly 300 inmate on Jan 3, 2023, but I doubt it.)\n\n\n\n\nAn even harder example\nThe New York Times maintains a map with the vaccination rates for various demographic groups by county on its website. At first, the Times didn’t provide a Github repo for the data. How can we extract the data from this map?\nThe easiest way would be to see if it contains a json miracle!\n\nOpen your inspector panel\nCopy and paste the link to the map page, and open it in your Chrome browser with the inpsectors showing.\nSwitch to the network tab. (If you opened the map before opening the inspector, reload it now. )\n\nYikes! The “Fetch /XHR” button doesn’t help us much here. There are too many different json files to check. We could look one by one and see if they’re right, but sometimes that’s just too hard. Instead,\n\nOpen the “Search” button on your inspector (it’s different from the Filter), and type in a county name (this one is “Maricopa”). You should see only a few of them. The most promising is the “doses_county.json”, so try that one first:\n\n\n\n\nnyt example\n\n\nThis time, it’s hard to find the item in the list of files in the browser. Instead, right-click in the “Preview” area, and copy the object. You can paste that into the box in the JSON to csv converter instead of entering a URL.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html#no-json-no-problem-maybe",
    "href": "start-scrape-nocode.html#no-json-no-problem-maybe",
    "title": "7  Scraping without programming",
    "section": "7.3 No json? No problem (maybe)",
    "text": "7.3 No json? No problem (maybe)\nYou may not be able to find a json file – either it’s too hard to find, or it’s not useful, or it doesn’t exist. For a simple page, there’s no problem getting the data in Google Sheets. (This is one area where Excel lags behind Google Sheets.) We’ll go into HTML tags in more depth in the next chapter, but if your data is held in a table or structured list, you can import it directly into Google sheets.\nNote that this trick is really only useful if your page doesn’t change a lot, or if you just want a one-time snapshot. It doesn’t automatically update, and I don’t know how to capture changes – it would involve a Google scripting program, which I don’t know how to do. I’ve never learned because I usually only gather data for my own use, and it’s easier to program it than to finagle Google Sheets.\nThe trick to using Google Sheets is to find a table tag (&lt;table&gt;) or a list tag (&lt;ul&gt; or &lt;ol&gt;) that contains the data you want.\nHere’s an example, taken from a previous year’s MAIJ cohort: Reporters wanted to know whether Scottsdale was relatively unique in its city council structure, which has no districts. All members are at-large. Some research suggests that this disempowers non-white or less wealthy areas, because more privileged residents are often more active in local politics.\nThe reporters knew it was rare, but one question nagged at them: Was Scottsdale the largest city in the nation with a purely at-large council? That would make a nice tidbit for the story, but it wasn’t worth a major data collection endeavor.\nBallotpedia, a crowdsourced website with information on local governments, had collected a page of city council officials in the 100 largest cities in the US. Extracting this information into a structured table, then using regular expressions, could help make that a relatively simple job. This could even be done in Google Sheets, which also has a regular expression implementation. Because it’s so rare, just getting a list of cities that had no district or ward membership would give them a place to start looking up populations.\nThis information is stored in an HTML table, identified by the “\n” element.\nRight-click on the page, and open your inspector. It looks like a mess, but you can search for tables using a simple “Find” using Cmd (or Ctl) -F.\nYou may notice it says you can find by string, selector or XPath.\nIn the box, enter “&lt;table” (with the opening “&lt;”, but no closing one.). You should see “1 of 12” in the result box. As you go through the list, the currently selected table will be highlighted. When you hit “3 of 12”, you’ll notice that the browser has selected the table you want. That’s the information we need.\nOpen a Google Sheet, and copy the page URL to cell A1. This just makes it easier to construct the formula to extract the table.\nIn cell A3, enter the following formula:\n      \n      =ImportHTML(A1, \"table\", 3)That means, “Go to the web address listed in cell A1, look for”table” tags, then return whatever is in the third one.”\n\n\ngooglesheet\n\nWhen you hit “enter” the whole table will populate on your Google Sheet. Unfortunately, you can’t get the link to the city from this method, which means you don’t have a good way to extract a city name. We’ll come back to this when we go to scraping in R. (There is a way to get this in Google Sheets, but it’s not very reliable – it will choke as soon as it encounters a missing URL.)But if you just need the text of a table or list in a spreadsheet, this is an easy way to get it. (To get a list from an “ol” or “ul” (ordered and unordered lists) tag, use “list” instead of “table”.)\n7.4 Recap\nSometimes – especially on modern websites that create interactive elements on the fly – the data you need is already sitting on your computer. In fact, it’s quite hard to scrape those in other ways because the HTML is created when it’s loaded into your browser.\nBut when it’s not, there may be another simple way to get the content.\nThe problem is that getting the content without programming can leave you unsatisfied because you can only get the text, not any of the underlying information. The next chapter shows you one method of getting more information from a web page using CSS selectors.\nI sometimes use a Chrome extension called “Chrome Scraper” to get slightly more complex information out of a website, which uses a language called XPath to parse a web page. It’s harder than the CSS selector method, though, so I’m skipping it for now.\n\n\n\n\n\n“application programming interface”↩︎\nIn R, our style was to name columns in lower case with words separated by underscores. In Javascript, the custom is usually called “camel case”, with words smushed together and the first letter of each upper cased. It’s just a custom, not a rule.↩︎\nI’m hiding names of people to the extent possible, and won’t list them in text here - they’ll only be in the images. Instead, I’ll show pictures of how to find the json when a name is necessary. Although this book is probably not indexed by Google, it’s possible that it could be some day, and I don’t want their names to show up in a Google search.↩︎\n\n\n  \n      \n         6  Build your own database\n                \n  \n  \n      \n        Spreadsheets",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html#recap",
    "href": "start-scrape-nocode.html#recap",
    "title": "7  Scraping without programming",
    "section": "7.4 Recap",
    "text": "7.4 Recap\nSometimes – especially on modern websites that create interactive elements on the fly – the data you need is already sitting on your computer. In fact, it’s quite hard to scrape those in other ways because the HTML is created when it’s loaded into your browser.\nBut when it’s not, there may be another simple way to get the content.\nThe problem is that getting the content without programming can leave you unsatisfied because you can only get the text, not any of the underlying information. The next chapter shows you one method of getting more information from a web page using CSS selectors.\nI sometimes use a Chrome extension called “Chrome Scraper” to get slightly more complex information out of a website, which uses a language called XPath to parse a web page. It’s harder than the CSS selector method, though, so I’m skipping it for now.",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "start-scrape-nocode.html#footnotes",
    "href": "start-scrape-nocode.html#footnotes",
    "title": "7  Scraping without programming",
    "section": "",
    "text": "“application programming interface”↩︎\nIn R, our style was to name columns in lower case with words separated by underscores. In Javascript, the custom is usually called “camel case”, with words smushed together and the first letter of each upper cased. It’s just a custom, not a rule.↩︎\nI’m hiding names of people to the extent possible, and won’t list them in text here - they’ll only be in the images. Instead, I’ll show pictures of how to find the json when a name is necessary. Although this book is probably not indexed by Google, it’s possible that it could be some day, and I don’t want their names to show up in a Google search.↩︎",
    "crumbs": [
      "Reporting with data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scraping without programming</span>"
    ]
  },
  {
    "objectID": "xl.html",
    "href": "xl.html",
    "title": "Spreadsheets",
    "section": "",
    "text": "Introduction\nSome people consider using spreasheets the table stakes for getting into data journalism. It’s relatively easy to see what you’re doing and you can easily share your work with your colleagues. In fact, pieces of the Pulitzer-Prize winning COVID-19 coverage from The New York Times was compiled using an elaborate and highly tuned set of Google spreadsheets with dozens of contributors.\nThis guide uses Excel for the Mac from Office 365, which most newsrooms still have. The reason is that they’re a little easier to get around and in particular have more options for pivot tables – a crucial part of the table stakes. But Google sheets shine elsewhere in this book, particularly when it comes time to scrape websites or import non-tabular file formats like JSON.\nExcel in Windows is very different – it has much more capability for working with large and more complex data, and provides better tuning for import and other operations.\nMost of the screen shots and instructions are created with a MacOS Monterey. Some come from earlier Mac versions, but are largely the same now. Windows users should replace any instructions for using the CMD- key with the CTL- key. There is a table that compares keystrokes for Apple desktops, laptops and Windows machines for Excel at the bottom of An Excel Refresher",
    "crumbs": [
      "Spreadsheets"
    ]
  },
  {
    "objectID": "xl-refresher.html",
    "href": "xl-refresher.html",
    "title": "8  An Excel Refresher",
    "section": "",
    "text": "8.1 Re-learning Excel from the ground up\nThe areas of the spreadsheet have different visual clues, and learning to read them will make your life much easier.\nThis image shows some key areas on the screen when you’re just viewing the sheet:\nThis is how it changes when you’re editing",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-refresher.html#re-learning-excel-from-the-ground-up",
    "href": "xl-refresher.html#re-learning-excel-from-the-ground-up",
    "title": "8  An Excel Refresher",
    "section": "",
    "text": "The spreadsheet grid\n\n\n\nWhen you start up a spreadsheet, you’ll see letters across the top and numbers down the side. If you ever played Battleship, you’ll recognize the idea – every little square, or cell, is referenced by the intersection of its column letter and row number:\nB2 is the cell that is currently active. You can tell because it’s outlined in the sheet and it’s shown on the upper left corner.\n\n\nMouse shapes\n\n\n\n\n\n\n\nBFWPS: The Big Fat White Plus Sign. This is the default shape, and you can never get into trouble when you see it\n\n\n\nBFwPS\n\n\n\n\nThe Copy Tool, or the thin black cross. When you see this, you’ll copy anything that’s selected. This can be good or bad.\n\n\n\ncopy\n\n\n\n\nThe Evil Hand. (In Windows, this is the Evil Arrow). If you use this symbol, you will MOVE the selection to a new location. This is very rarely a good idea or something you intend.\n\n\n\nevil hand\n\n\n\n\n\n\n\nSelecting cells and ranges\nSpreadsheets act only on the cells or regions you have selected. If you begin typing, you’ll start entering information into the currently selected cell.\nTo select: Hold the BFWPS over the cell and clice ONCE – not twice. Check the formula bar to make sure you’ve selected what you think you’ve got. You can also look at the bottom right of your spreadsheet for more information.\nYou’ll often work with ranges of cells in formulas. These are defined by the corners of the area you want to work on – often a column of information. In the example below, the range is A1:B6, with the “:” referring to the word “through”.\nTo select a group of cells and act on them all at once: Hover the BFWPS over one corner, click ONCE and drag to the diagonal corner. Make sure the Evil Hand is nowhere to be seen. The entire area will be shaded in except for the currently selected cell. Look at the upper right corner to see how many rows and columns you selected.\n\n\n\n\nTo select a column or row : Hover the BFWPS over the letter at the top of the column. For a row, hover it over the row number in the margin\n\n\nReading the screen\n\n\n\n\n\n\nready\n\n\n\n\n\n\nediting\n\n\n\nEntering data\nSelect the cell and start typing. The information you type won’t be locked into the cell until you hit the Return / Enter key, or move your selection to another cell. Hit “Escape” to cancel the entry.\nYou can’t do a lot of things while you’re editing, so if you have a lot of greyed out menu items, look at your formula bar to see if you are still editing a cell.\nIf you’re having trouble getting to a menu item or seeing the result of your work, try hitting “Escape” and try again. You may not have actually entered the information into the sheet.\n\n\nLocking in headings\nAs your spreadsheet grows vertically with more rows, you’ll want to be able to see the top all the time. When it grows horizontally with more columns, you’ll probably want to see columns in the left, such as names. This is called “Freezing Panes” – you freeze part of the page so it stays in place when you move around.\nSelect the corner that you want frozen. For example, if you want the first three columns frozen (A:C) and the first row frozen (1), then select the cell in D2. This is the first cell that will move, and everything to the left of it and above it will stay on the screen.\n\n\n\nfreeze panes\n\n\n\n\nFormatting tricks\n\nUse the buttons or the format dialog box to make numbers easier to read.\nIf a column is filled with a lot of text, select the column and look on the Home ribbon next to the formatting area for “Wrap Text”. This means that when you double-click to widen a column, it will get taller, not wider. This is good when you need to save valuable real estate on the screen.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-refresher.html#getting-started-with-a-dataset",
    "href": "xl-refresher.html#getting-started-with-a-dataset",
    "title": "8  An Excel Refresher",
    "section": "8.2 Getting started with a dataset",
    "text": "8.2 Getting started with a dataset\nSLOW DOWN! Don’t do anything until you understand what you have in front of you and can predict what your next mouse click will do to it.\nMost data we encounter was created by someone else for some purpose other than ours. This means that you can’t assume anything. It may not be complete. It may be inaccurate. It may mean something completely different than it appears at first blush.\n\nFirst steps\n\nDocument where you got the spreadsheet and how you can get back to the original.\nRead anything you can about what it contains. Look for documentation that comes with the data.\nSave the original into a safe place with its original name and metadata. Work on a copy.\nIf the spreadsheet shows #### instead of words or numbers, widen your columns. If it shows 7E-14 or something like that, format them as numbers, not “General”.\nCheck your corners – look at the top left and bottom right. Is the data all in one area? Are there footnotes or other non-data sections mixed in? We’re going to want to fix that later.\n\n\n\nInterview your data\n\nHeadings\nThe most fraught part of data reporting is understanding what each column actually means. These often have cryptic, bureaucratic names. You may need to go back to the source of the data to be sure you actually understand them.\nIf your data doesn’t have any headings, that’s going to be your first priority. In effect, you’ll need to build what we call a data dictionary or record layout if one hasn’t been provided. Many reporters create these as a page in a dataset.\n\n\nUnit of analysis\nA unit of analysis refers to the items that are listed in the rows of your dataset. Ideally, every row should be at the same unit of analysis – a person, an inspection, or a city, for example. Summaries should be separated by a blank row, or moved to a different sheet. Think of this as the noun you’d use to describe every row.\n\n\nRow numbers\nThe data was probably given to you in some sort of natural sort order. Different computer systems sort differently – some are case-sensitive, others are not. It may depend on when and where the data as created! The order of the data may even depend on a column you don’t have. If you don’t do something now, you’ll never be able to get back to the original order, which could have meaning for both the agency and for fact-checking.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-refresher.html#video-walkthrough",
    "href": "xl-refresher.html#video-walkthrough",
    "title": "8  An Excel Refresher",
    "section": "8.3 Video walkthrough",
    "text": "8.3 Video walkthrough\nThese first steps, along with adding an ID row, are shown here. You can follow along with the same dataset.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-refresher.html#keyboard-shortcuts",
    "href": "xl-refresher.html#keyboard-shortcuts",
    "title": "8  An Excel Refresher",
    "section": "8.4 Keyboard shortcuts",
    "text": "8.4 Keyboard shortcuts\nFor Mac users, it’s much easier to use Excel if you override the action of function keys while you’re in the program. In your Mac’s System Preferences, choose Keyboard, and select the box that says, “Use F1, F2, etc. as standard function keys.” (NOTE: If you have a MacBook Pro with a touch bar (circa 2017-2020 or so), this option may not be there. Instead, go into the Shortcuts section of the keyboard options and turn off all of the options for Mission Control. Those are the ones that interfere with Excel.)\n\nOnce you’ve done that, these keyboard shortcuts will work:\n\n\n\n\n\n\n\n\nTo do this\nWindows or IMac\nMacbook\n\n\n\n\nEdit a cell\nF2\nCtl-U or F2\n\n\nToggle between absolute and relative references\nF4\nCtl-T or F4\n\n\nInsert cut cells\nCtl+\nCtl+\n\n\nDelete a cell\nCtl-\nCtl-\n\n\nSelect the top left of a spreadsheet\nCtl-Home\nCtl-Fn-Left arrow\n\n\nMove to the bottom right of a spreadsheet\nCtl-End\nCtl-Fn-Right arrow\n\n\nSelect a region (a contiguous rectangle of cells that are filled out)\nCtl -*\nCtl-Shift_spacebar\n\n\n\nYou should practice getting around a spreadsheet efficiently, since scrolling with the mouse while selecting is a lesson in frustration.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-refresher.html#footnotes",
    "href": "xl-refresher.html#footnotes",
    "title": "8  An Excel Refresher",
    "section": "",
    "text": "This guide is done using a Mac. Windows machines will be a little different, mainly because you’ll have more choices in most menus. The Mac CMD key is the same as the Windows CTL key.↩︎",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Excel Refresher</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html",
    "href": "xl-filter-sort.html",
    "title": "9  Sorting and filtering to find stories",
    "section": "",
    "text": "9.1 A sorting miracle\nAfter Ferguson, Mo., police killed Michael Brown in 2014, advocates and journalists began examining the racial and ethnic gap between police departments and the communities they served. The New York Times found a 7-year-old survey conducted by the Justice Department that allowed it to compare the data for major cities in a standalone graphic that it published later that year.\nWhen newer data reflecting departments’ makeup in 2012 was released a year later, Matt Apuzzo and I hoped it would show some differences. It didn’t. So we were left trying to find news in the data that was clearly of public interest.\nAfter matching up the demographics of police departments with their cities, I started sorting, filtering and Googling. Could there be news in the outliers on the list? Which departments most closely represented their communities? Which ones had unusually large gaps?\nI quickly stumbled on telling anecdote to frame the story: Inkster, Mich. had one of the least representative departments in the country, and had recently hired a new police chief to help mend the department’s fraught relationship with its largely African-American community. Where had he come from? Selma, Ala., one of the most representative police departments in the nation. Interviews with the chief, William T. Riley III, suggested one reason for some cities’ disparities: there was no state or federal money to pay for training new police officers.\nThe story, “Police Chiefs, Looking to Diversity Forces, Face Structural Hurdles” helped explain the persistent gap between the makeup of police in some areas and the communities they served.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#a-sorting-miracle",
    "href": "xl-filter-sort.html#a-sorting-miracle",
    "title": "9  Sorting and filtering to find stories",
    "section": "",
    "text": "Chief William T. Riley III. Credit: Laura McDermott for The New York Times",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "href": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.2 Sorting and filtering as a reporting tool",
    "text": "9.2 Sorting and filtering as a reporting tool\nSorting and filtering can:\n\nNarrow your focus to specific items that you want to examine in your story.\nShow you rows containing the highest and lowest values of any column. That can be news or it can be errors or other problems with the data.\nLet you answer quick “how many?” questions, with a count of the rows that match your criteria. (In the next lesson, you’ll see that pivot tables, or group-by queries, are much more powerful for this in most cases.)",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#example-data",
    "href": "xl-filter-sort.html#example-data",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.3 Example data",
    "text": "9.3 Example data\n\n\nData from the Washington Post for use in this tutorial\nDocumentation from the Post’s github site. This data refers to the original “V1” data.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe column names and We will look at the documentation under “V1” in their github repo . The data was last updated in early 2022, before the Post made changes. This copy includes all shootings through the end of 2020 – 2021 was removed because too much of the data downloaded at the time was missing.\nThis tutorial has screen shots from a slightly different version of the data, so your answers won’t match precisely.\n\n\nThe data for this and several other chapters is the Washington Post’s public data collection of police shootings in the U.S. It includes the nation’s best guess about each fatal police shooting since 2015. There are a couple of caveats:\n\nIt excludes deadly police interactions other than shooting a firarem at the suspect. Any strangulation, car crashes, Tasers without guns or other methods are excluded. You will not find Geore Floyd in this data.\nIt is based primarily on news reports and the results public records requests so it often contains the story as told by police. We know that many of those reports are sugar-coated at best, and lies at worst.\nThe Post says this is a list of fatal shootings, but doesn’t say what happens if more than one person is killed. The 2019 shooting of D’Angelo Brown & Megan Rivera in West Memphis is shown as two rows in the data even though it was one event. So each row might be considered a shooting “victim”, a “suspect” or a shooting “fatality” rather than a “shooting”. The Post’s documentation suggests that this is the case, but finding that double shooting confirms it.\n\nThe original data download link is https://github.com/washingtonpost/data-police-shootings/releases/download/v0.1/fatal-police-shootings-data.csv. The screenshots in this tutorial may not match exactly to what you get on their data.\nThere is a page of “documentation” in the Excel copy used in this tutorial that walks through the sources and details of each column.\nIt’s a good example set for us because it’s been used as the basis of many stories, it has at least one of each data type that we plan to deal with in Excel, and it is well documented on the Post’s github site.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#understanding-data-types",
    "href": "xl-filter-sort.html#understanding-data-types",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.4 Understanding data types",
    "text": "9.4 Understanding data types\nWhen you open the spreadsheet, the first thing to notice is its granularity. Unlike Census or budget spreadsheets, this is a list capturing specific characteristics of each fatality Each column has the same type of data from top to bottom. Those types are:\n\nText. Text or “character” columns can come in long or short form. When they are standardized (the values can contain only one of a small list of values), they’re called “categorical”. If they’re more free-form, they’re might be called “free text”. The computer doesn’t know the difference, but you should. The Post data has examples of both. In spreadsheets, text is left-justified (they move toward the left of the cell and will line up vertically at the beginning)\nNumbers. These are pure numbers with no commas, dollar signs or other embellishments. In Excel, as we’ll see in the computing section, these can be formatted to look like numbers we care about , but underneath they’re just numbers. Adding up a column of numbers that has a word in it or has missing values will just be ignored in Excel. It will trip up most other languages. These are right-justified, so the last digit is always lined up vertically.\nLogical: This is a subset of text. It can take one of only two values – yes or no, true or false. There is no “maybe”.\nDate and times: These are actual dates on the calendar, which have magical properties. Underneath, they are a number. In Excel, that number is the number of days since Jan. 1, 1900. They can also have time attached to them, which in Excel is a fraction of a day. What this means is that the number 44,536.5 is really Dec. 6, 2021 at noon. In Excel, you use a format to tell the spreadsheet how you want to see the date or time, just the way you look at dollar values with commas and symbols. (If you get a spreadsheet with a lot of dates of 1/1/1900, it means there is a 0 in that column, which is sometimes a fill-in for “I don’t know.”)\nHere’s a picture of a date that is shown in a variety of formats.\n\n\n\ndate formats\n\n\nAll of these are the same, underlying value – the number at the left. Notice that all of these are right-justified.\nThis means that when you see “Friday, December 10”, the computer sees 44540.87431. When you put the dates in order, they won’t be alphabetized with all of the Fridays shown together. Instead, they’ll be arranged by the actual date and time.\nIt also means that you can compute 911 response times even when it crosses midnight, or or compute the someone’s age today given a date of birth. Keeping actual calendar dates in your data will give it much more power than just having the words. (Excel uses the 1st of the month as a stand-in for an actual date when all you know is the month and year.)",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#working-with-excel-tables",
    "href": "xl-filter-sort.html#working-with-excel-tables",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.5 Working with Excel “tables”",
    "text": "9.5 Working with Excel “tables”\nExcel lets you put any type of data anywhere on your spreadsheet. To bring a little order to the chaos, it allows you to turn your data into a “table”, which is set up for sorting and filtering. It enforces some data types on you, and deals with missing information more smoothly. It is designed for tabular data without empty rows or columns, and where there is nothing else on the sheet.\nPut your cursor somewhere in the table, then use the “Format as table” button on the home screen. Check to make sure the “My table has headers” is checked.\n\n\n\nsort\n\n\n\nSorting rows\nSorting means rearranging the rows of a data table into a different order. Some reporters take a conceptual shortcut and call this “sorting columns”. That thinking will only get you into trouble – it lets you forget that you want to keep the rows in tact while changing the order in which you see them. In fact, in other languages it’s called “order by” or “arrange” by one or more columns – a much clearer way to think of it.\nIn Excel, look for the sort options under the Data tab at the top of your screen. In this case, sorting from oldest to newest gives you a list of the fatalities in chronological order, including the time of day.\nTo sort your data, put your cursor in one of the cells within your data area, and choose Data…Sort. Please don’t use the A-&gt;Z or Z-&gt;A buttons!\n\n\nAdding fields to the sort\nAdding more columns to the sort box tells Excel what to do when the first one is the same or tied. For example, sorting first by state then by date gives you a list that shows all of the events by state in sequence:\n\n\n\n\nFiltering\nFiltering means picking out only some of the rows you want to see based on a criteria you select in a column. Think of it as casting a fishing net – the more filters you add, the fewer fish will be caught.\nWhen you created the table, it also created little drop-down arrows on the top row. If you can’t see them, use CTL-HOME or CTL-UP on the first column to get yourself back to the top. Each filter you select adds more conditions, narrowing your net.\nTo find fatalities that involved a firearm with a Taser, use the drop-down menu under manner_of_death select it. (This is an example of naming a column in an unexpected way. Usually, a “manner” of death relates to the circumstances such as accident, suicide or homicide. It’s why you can’t count on understanding the column names without a crib sheet from the data’s maker, called a data dictionary or record layout. The Post’s crib sheet is excellent!)\nWhen you do this, notice that the bottom left briefly shows you the number of rows that matched your filter, and the line numbers turn blue. Any rows that don’t match your filter hidden.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis method works for small-ish and simple-ish columns. If your column has more than 10,000 different entries, such as names or addresses, only the first 10,000 will be considered. We only caught these for stories when someone did a fact-check using a different method of filtering. If your column has a lot of distinct entries, use option that says “Choose One”, and then use the “Contains” option. Better yet, don’t use filtering for counting things at all.\n\n\nAdd more filters to narrow down your list of cases even more. For example, the New York Times ran a series of stories in 2021 about unarmed people shot by police. One story was about those who were fleeing by car. Here’s one way to get a preliminary list of those cases:\n\nRemove any filter you already have on.\nTurn on the filters again if you turned them off.\nChoose “unarmed” under armed and “car” under flee.\n\n(Of course, the Times didn’t stop there in trying to find more cases and teasing out more of them from this and other data. But this is a start. )\n\n\nDifferent kinds of filters\nThere are several options under the filter box, depending on what data type in in the column. In numeric columns, you can get top and bottom lists. Dates will automatically collapse into years, then months, then days to let you choose more efficiently.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#video-of-sorting-and-filtering-with-salaries",
    "href": "xl-filter-sort.html#video-of-sorting-and-filtering-with-salaries",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.6 Video of sorting and filtering with salaries",
    "text": "9.6 Video of sorting and filtering with salaries\nThis video goes through many of the details of sorting and filtering. Follow along using this spreadsheet of Phoenix city salaries. It’s from a different year, but the idea is just the same.\nNote that in this case, the original order of the dataset was alphabetical, except lower-case names came at the very end. It would be very hard to get back to this order in a spreadsheet if you didn’t have that leftmost column of numbers that indicated the original order.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-filter-sort.html#faq",
    "href": "xl-filter-sort.html#faq",
    "title": "9  Sorting and filtering to find stories",
    "section": "9.7 FAQ",
    "text": "9.7 FAQ\n\nHow do I turn off all of my sort and filters\nIn the data tab, chose “Clear” (the funnel with the red “X”) to remove all of the filters and sorts on your table.\n\n\nWhere is the button to filter columns?\nSometimes you don’t want to see all of your columns – there are too many and they’re getting confusing. There is no column filter in Excel. (You’ll see how to filter, or “Select”, columns from a dataset in standard programming languages later.)\nInstead, you can hide the columns you don’t want to see. When columns and rows are hidden, they generally won’t copy to a new sheet.\n\n\nI’m getting weird questions and alerts about sorting\nSlow down and read the alert. There are two common types of alerts in sorting, since it has the potential to wreck your spreadsheet.\nThe first comes if you selected an entire column, and then just hit the button that says “A-Z” with the arrow. Excel won’t let you do that if it’s formatted as a table, but it will if it’s just a normal spreadsheet. This alert asks you if you REALLY want to sort only the column you’ve selected, separating its meaning from the rest of the rows. The answer is NO. Always. Expand the selection as Excel wants you do to by default.\n\n\n\nfilter date\n\n\nThe other comes when you have numbers that are treated as text. This is a tricky question, and a properly tidied spreadsheet should avoid it most of the time. If you have the same type of data in each column, the answer to this question shouldn’t matter. If not, neither one will give you what you want.\n\n\nI want to get rid of my data table\nYou can revert to the a plain old spreadsheet by selecting any cell within your table, then looking for the “Table” tab at the top of your screen. Choose the option that says “Convert to Range”.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sorting and filtering to find stories</span>"
    ]
  },
  {
    "objectID": "xl-pivot.html",
    "href": "xl-pivot.html",
    "title": "10  Grouping with pivot tables",
    "section": "",
    "text": "10.1 Summarizing with groups\nSummarizing a list of items in a spreadsheet is done using pivot tables. In other languages, it’s considered “aggregating” or “grouping and summarizing”. Think of pivot tables and grouping as answering the questions, “How many?” and “How much?”. They are particularly powerful when your question also has the words “the most” or the “the least” or “of each”. Some examples:",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grouping with pivot tables</span>"
    ]
  },
  {
    "objectID": "xl-pivot.html#summarizing-with-groups",
    "href": "xl-pivot.html#summarizing-with-groups",
    "title": "10  Grouping with pivot tables",
    "section": "",
    "text": "Which Zip Code had the most crimes?\nWhat month had the least total rainfall?\nHow much did each candidate raise last quarter?\nIn playing cards, how many of each suit do I have in my hand?\nOn average, are Cronkite students taller or shorter than in other schools?\n\n\nConfusing grouping with sorting or arranging\nMany reporters confuse this summarization with “sorting”. One reason is that this is how we express the concept in plain language: “I want to sort Skittles by color”.\nBut in data analysis, sorting and and grouping are very different things. Sorting involves shuffling a table’s rows into some order based on the values in a column. In other languages, this is called arranging or ordering, much clearer concepts. Grouping, which is what pivot tables do, is a path to aggregating and computing summary statistics such as a count (the number of items), sum (how much they add up to), or average for category. It means “make piles and compute statistics for each one.”\n\n\nWhen to use filter vs. pivot tables\nSomething that trips up beginners is a desire to see details and totals at the same time, which is more difficult than it sounds.\nA filter is used to display your selected items as a list. You’ll get to see all of the detail and every column. As a convenience, Excel shows you how many items are in that filtered list. That’s great when you want to just look at them, or get more information about them. For instance, if you had a list of crimes by ZIP code, you might just want to see the list in your neighborhood – where, exactly, were they? When did they happen? Was it at night or the morning? What crimes happened on which blocks?\nA pivot table is used when you just want to see summaries – does my ZIP code have more crime than others? Are robberies more common than car theft in my Zip code, and how does that compare to others?\nIn practice, you’ll go back and forth between summary and detail. They’re both important, just different.\n\n\nMotivational exercise\nA lot of reporters try to do everything with filters. Once they learn pivot tables, they try to do everything with pivot tables. They’re two different animals – filtering is used for detail, and grouping (or pivot tables) are for summary. Here’s one way of understanding what pivot tables do before you try to make one.\nIf you wanted to know how many people of each race/ethnicity were shot and killed, here’s one way you can do it:\n\nUsing a data table, use the filter the column called “Ethnicity” to show only “Black non-Hispanic” victims.\n\n\n\nYou should see something like this at the bottom of your screen, showing 1444 of 5945 records shown.\n\n\n\n\n\nfilter results\n\n\n\n\n\nWrite that down on a piece of paper, or start a new sheet in your workbook called “ethnicity”, and create a small data area with the columns called “Ethnicity”, “# of shootings”, “% of total”.\nRepeat the process with each ethnicity, entering or writing down the results of each of them.\nNow, for each ethnicity, compute the percent of total – or, the number of rows you found divided by 5,945 expressed as a percent.\n\nIn the end, you would have a page that looks something like this (or your own chicken-scratching with the same numbers):\n\n\n\nhandmade pivot\n\n\nAnd if you’re asking yourself, “why is this so much work? Isn’t there an easier way?” , the answer is to try a pivot table. It does all that work for you.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grouping with pivot tables</span>"
    ]
  },
  {
    "objectID": "xl-pivot.html#tutorial",
    "href": "xl-pivot.html#tutorial",
    "title": "10  Grouping with pivot tables",
    "section": "10.2 Tutorial",
    "text": "10.2 Tutorial\n\nA Skittles example\n\n\n\n\n\n\n\nErrata\n\n\n\nMake sure that the column you choose to put in the “Values” area to count is always filled out – otherwise it will skip them.\n\n\n\n\nSetting up the pivot table\nStart with your cursor somewhere in your data , and choose Insert, then Pivot table\n\n\n\ninsert menu\n\n\nIf all goes well, it will look like your data disappeared. It didn’t – you’re just on a new page. Here’s what it looks like:\n\n\n\npivot menu\n\n\n\n\nCounting , or “how many”?\nThe section on the right gives you an outline of what to do. The section on the left will get filled in as you make your pivot table. If you want to see the number of fatalities by ethnicity, drag that column into the “Rows” area, then drag something that’s always filled out into the Values area (state is a safe one in this data).\n\n\n\n\n\n\nImportant\n\n\n\nBe sure to ALWAYS use something that has something filled in all the time for this. If you look at the filter, it must not have an option at the bottom that says (Blanks). If you ignore this, your answer will be wrong, since the calculation will only count filled-in cells.\n\n\n\n\n\nPercents of total\nIt’s hard to compare raw numbers unless they’re really small. Instead, we’d like to know what percent of fatalities by ethnicity. Right-click on any number in the pivot table, and choose “Show data as…” , then choose “Percent of Column total”.\n\nTo remove it, right-click on it and choose “Remove”Count of state2”“.\n\n\nMore columns\nSuppose you’d like to see the number of fatalities by year, with the years across the top and the ethnicity down the sides. Drag the year variable into the column area . Sorting can get hinky on pivot tables, but in this case it will work to put the largest number on top. This won’t work with percentages – it still sorts by the underlying number.\n\n\n\nEven more detail\nSay you wanted to see each city’s total shootings by year. Which one had the most last year, and which one had the most overall?\nThis is actually really hard in a pivot table, because there are cities with the same names in different states. It means you’d need to have a pivot table with TWO columns down the side, and one across the top. Here’s my attempt at getting there:\n\n\n\nbadsort\n\n\nThis is after some fiddling with the formats, and I still can’t sort properly – the city “Phoenix”, including those in Maryland and Arizona, had the second-highest number of shootings. We can’t sort by the combination of city and state. (Don’t try to get something that looks like this on your own – I can’t even reproduce it exactly because I’d fiddled around trying to get something that I wanted to see in this example. )\nYour choices in Excel are limited: Copy and paste the values of the pivot table into a new sheet and sort there, or create a new variable by concatenating the name of the city and state into one column.\n\n\nGo back to your raw data\nBut say you wanted to look into the 15 Phoenix, AZ shootings from 2020. Your instinct might be to filter your pivot table and try adding more items to the columns and rows:\n\n\n\npivot add info\n\n\nBut this is what your filters were made for! Return to your original data, and set the filters so you can see ALL of the details about the small list of items.\n\n\n\n\nfilter results\n\n\n\n\nThe big picture\nPivot tables and aggregation with grouping are good for narrowing down the items you want to examine more closely, and for compiling summary statistics about your data.\nBut filters are much better for examining the full range of information about a small number of examples.\nIn practice, you’ll go back and forth between summary and detail. You need them both.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grouping with pivot tables</span>"
    ]
  },
  {
    "objectID": "xl-pivot.html#tldr",
    "href": "xl-pivot.html#tldr",
    "title": "10  Grouping with pivot tables",
    "section": "10.3 TL;DR",
    "text": "10.3 TL;DR\nHere’s a video with the same material:",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grouping with pivot tables</span>"
    ]
  },
  {
    "objectID": "xl-pivot.html#faq",
    "href": "xl-pivot.html#faq",
    "title": "10  Grouping with pivot tables",
    "section": "10.4 FAQ",
    "text": "10.4 FAQ\n\nEverything disappeared!\nIf you select something outside of that pivot table on the left, the menu on the right disappears. Select something in the pivot table area and it will likely come back.\n\n\nI have too many columns\nIf you want two sets of statistics – say, number of fatalities and percent of fatalities – across the top, it can get very wide and confusing very quickly. One alternative is to change it into more of a vertical rectangle by dragging the “Values” element from the columns to the rows on the right. (This only shows up when you have two calculations being made.)\n\n\nI want to sort by percents, not numbers\nYou can’t.\n\n\nThings aren’t adding up\nYou have to be super careful about which column you use to Count things – it has to always be filled out (there can’t be any blanks). Go through the filters and find one that doesnt have (Blanks) at the bottom to be sure.\n\n\nIts a crazy number!\nYou might have dragged a numeric column into the “Values” area. Check to see if it says “Count” or “Sum”. Change it to “Count” if it has something else on it, unless you wanted to add up that column.\n\n\nThis is so frustrating - I can’t get what I want\nRight? It’s time to go to a programming language!",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grouping with pivot tables</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html",
    "href": "xl-formulas.html",
    "title": "11  Formulas in Excel",
    "section": "",
    "text": "11.1 Formulas in spreadsheets\nWhether you use Excel or Google sheets, remember that every formula begins with the equals sign (=). Rather than the values you want to work with in the formula, you’ll use references to other cells in the sheet.\nThe easiest formulas are simple arithmetic: adding, subtracting, multiplying and dividing two or more cells. You’ll just use simple operators to do this:\nHere’s what a spreadsheet looks like while editing some simple arithmetic:\nThe other kind of formula is a function. A function is a command that has a name, and requires arguments – usually the cell addresses or the range of addresses that it will act on. Every programming language has functions built in and many have extensions, or packages or libraries, that add even more as users find things they want to do more efficiently. You begin using a function the same way you begin a formula – with an = sign. Here are three common functions that create summary statistics for the numbers contained in a range of addresses. A range is a set of cells defined by its corner cell address: the top left through the bottom right.\nYou’ll usually use them on a single column at a time.\n…where “start” means the first cell you want to include, and finish means the last cell. Use the cell address of the first number you want to include , a colon, then the cell address of the last number you want to include. You can also select them while you’re editing the formula.\nHere’s an example of adding up all of the rows in a list by county:",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html#formulas-in-spreadsheets",
    "href": "xl-formulas.html#formulas-in-spreadsheets",
    "title": "11  Formulas in Excel",
    "section": "",
    "text": "operator\nsymbol\nexample\n\n\n\n\naddition\n+\n=A2+B2\n\n\nsubtraction\n-\n=A2-B2\n\n\nmultiplication\n*\n=A2*B2\n\n\ndivision\n/\n=A2/B2\n\n\n\n\n\n\n\nformula\n\n\n\n\n\n\n\nFormula\nWhat it does\n\n\n\n\n=SUM(start:finish)\nAdds up the numbers between start and finish\n\n\n=AVERAGE(start:finish)\nComputes the mean of the numbers\n\n\n=MEDIAN(start:finish)\nDerives the median of the numbers\n\n\n\n\n\n\n\n\nformula",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html#common-spreadsheet-arithmetic",
    "href": "xl-formulas.html#common-spreadsheet-arithmetic",
    "title": "11  Formulas in Excel",
    "section": "11.2 Common spreadsheet arithmetic",
    "text": "11.2 Common spreadsheet arithmetic\nThe budget document shows three years’ of data: The actual spending in the fiscal year that ended in 2016; the spending that was estimated for the end of fiscal year 2017; and the proposed spending for fiscal year 2018. The first page of the document shows these amounts for broad spending categories.\nYou may want to widen the columns and format the numbers before you start:\n::: {.content-visible .when-format=“html”}\n\n:::\n\nCheck the government’s math with SUM\nOur first job is to make sure the government has provided us data that adds up. To do that, we’ll SUM all of the departments’ spending. To add up the numbers from 2016, enter the following formula in cell C11, just below the number provided by the government:\n  =SUM(C2:C8)\n  and hit the enter key\nCopy that formula to the right. Notice how the formula changes the addresses that it is using as you move to the right – it’s adjusted them to refer to the current column.\n\nWhat’s wrong? The numbers for the budget 2018 don’t add up. (Hint: look at the page called “notes” for an explanation.)\n\n\nChange in spending\nThe increase or decrease in projected spending from 2017 to 2018 is just the difference between the two values, beginning in cell F3\n  new-old, or  =E2-D2\nWhen you copy it down, note how the references to each row also adjusted. In line 3, it’s E3-D3, and so on. Excel and other spreadsheets assume that, most of the time, you want these kinds of adjustments to be made.\n\n\n\nPercent change\nWe can’t tell the rate of growth for each department until we calculate the percent change from one year to another. Now that we already have the change, the percent change is easy. The formula is:\n  ( new - old ) / old\n\n  .. or just scream \"NOO\"\nThe new-old is already in column F, so all that’s left is to divide again. In grade school, you also had to move the decimal place over two spots, since the concept of percent change is “out of 100”. Excel formats will do that for you.\nRemember, it’s always (new-old)/old , NOT the big one minus the little one. Doing it correctly, the answer could be negative, meaning the value fell.\n\n\n\n\n“% change”\n\n\n\nWhen you’re done, you can format the answer as a percentage to get it into whole numbers.\nUntil you get used to it, there’s no harm in doing these calculations step by step. Excel won’t complain if you have extra columns. You can always hide them.\nIt’s also worth comparing the picture you get by looking at raw numbers vs. percentages. In our case, the budget for public safety is expected to rise by a whopping $102 million, but it’s a smaller percentage increase than other, smaller departments.\n\n\nParts of a whole: percent of total\nWe’d also like to know what portion of the total spending is eaten up by each department. To do that, we need the percent of total.\nIn our case, let’s use the total that the government gave us. In practice, you’d have to decide what to do if your figures didn’t match those provided by officials. You can’t assume that the total is wrong – you could be missing a category, or there could be a mistake in one of the line items.\nThe formula for percent of total is:\n  category / total\nAgain, Excel will multiply by 100, or move the decimal place over for you once you format.\nBut you have a problem: You either have to type in each row, or you get something like this if you try to copy:\n\n\n\n\nWrong way\n\n\n\nExcel has done its magic, adjusting the location of both the numerator and the denominator when you copied. You don’t have to type in each formula one by one, though. Instead, you’ll use anchors, known in spreadsheets as “absolute references”. Think of a dollar sign as an anchor or stickpin, holding down the location of part of your formula. If you put the stickpin before the letter in the formula, it holds the column in place. If you put it before the number, it holds the row in place. If you put it in both places, it holds the cell in place.\nSo our new formula for the percent of total is:\n\n\n\n\nE2/E$10",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html#while-were-at-it-two-kinds-of-averages",
    "href": "xl-formulas.html#while-were-at-it-two-kinds-of-averages",
    "title": "11  Formulas in Excel",
    "section": "11.3 While we’re at it: two kinds of averages",
    "text": "11.3 While we’re at it: two kinds of averages\nAlthough it doesn’t make a lot of sense in this context, we’ll go ahead and calculate the average or mean size of each department, and then calculate the median size.\nSimple average, or mean\nA simple average, also known as the mean, is skewed toward very high or very low values. Its formula is\n    sum of pieces / # of pieces that were summed\nBut in Excel, all we need is the word AVERAGE:\n    =AVERAGE(C2:C9)\nMedian\nIn Excel, you can get the median of a list of numbers by just using the formula, MEDIAN()\n  = MEDIAN(C2:C9)",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html#the-final-spreadsheet",
    "href": "xl-formulas.html#the-final-spreadsheet",
    "title": "11  Formulas in Excel",
    "section": "11.4 The final spreadsheet",
    "text": "11.4 The final spreadsheet\n\n\n\n\nfinal worksheet\n\n\n\nDoing simple calclutions like this on data that is provided to you by the government lets you ask better questions when you get an interview, and may even convince officials to talk with you. There’s a big difference between asking them to tell you what the budget numbers are, and asking them to explain specific results!",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-formulas.html#faqs",
    "href": "xl-formulas.html#faqs",
    "title": "11  Formulas in Excel",
    "section": "11.5 FAQs",
    "text": "11.5 FAQs\n\nExcel won’t let me copy my formula\nMake sure your formula is locked in by either hitting “Enter” or “Escape”. This is a common problem if you’re in the habit of double-clicking instead of selecting a cell. There are a lot things you can’t do while Excel thinks you’re still entering information.\n\n\nShould I use average or median?\nIt depends. Averages are easier to explain but can be misleading. Usually, if they’re very different, median will be a better representation of the typical person, city or department. Averages in these cases are more like totals.\n\n\nMy percents are small numbers with decimal points\nUse the format as a % button to move the decimal point over two places and insert the percentage symbol.\n\n\nMac Users: There’s some kind of weird image on top of my spreadsheet. Or some other very weird hiccup.\nI have no idea what this is, but it happens. Save your spreadsheet, close it and then re-open. It should go away.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Formulas in Excel</span>"
    ]
  },
  {
    "objectID": "xl-practice-noc.html",
    "href": "xl-practice-noc.html",
    "title": "12  Practice exercise",
    "section": "",
    "text": "12.1 Data source\nData download\nCity link to Notice of claims form and instructions to claimants\nBackgrounder on the data from Helen Wieffering\nThis dataset includes all “Notice of Claims” against the city of Phoenix between 2010 and 2020. These claims refer to damages that people say they suffered because of a problem in the government ranging from slip-and-fall in a city building to use of force by police. It was obtained by Helen Wieffering just after the end of the 2020 fiscal year, so many of the claims from that year will be unresolved. Although the names of the claimants are public record, they were not included in the data compiled here. Also missing is the court case number of any cases that went to court.\nMake sure to look at the “data_dictionary” sheet for the definitions of each column before you start.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Practice exercise</span>"
    ]
  },
  {
    "objectID": "xl-practice-noc.html#sort-filter",
    "href": "xl-practice-noc.html#sort-filter",
    "title": "12  Practice exercise",
    "section": "12.2 Sort / filter",
    "text": "12.2 Sort / filter\nI almost always go into the Excel preferences, and under “Tables & Filters” turn off the check that says “Use table names in formulas”. Sometimes it sticks, sometimes it doesn’t. Have no idea why.\n\nWhat is the orig_order (id) value of the largest PAID claim in the database (combined personal injury and property) ?\nWhat department and cause were associated with that payment?\nHow long did it take to resolve it?\nDescribe the most recent claim made against the police related to law enforcement activities, regardless of whether it’s been resolved.\nUsing your filter, determine how many paid claims were made for “Shootings”. in the type of claim.\nFind one other thing that you might want to research further that could make an interesting one-off story. These are distinct events that you’d like to know more about, not trends or patterns. This requires no calculation, just your news judgment. Base it solely on what you see in this data, not other research.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Practice exercise</span>"
    ]
  },
  {
    "objectID": "xl-practice-noc.html#pivot-table-practice",
    "href": "xl-practice-noc.html#pivot-table-practice",
    "title": "12  Practice exercise",
    "section": "12.3 Pivot table practice",
    "text": "12.3 Pivot table practice\n\nCreate the pivot table\n1, Create an empty pivot table from the data table.\n\nLook for the “Options” tab toward the top left, and turn off “Generate GetPivotData”. In the same tab, under “Options”, set error values to “N/A”, and set Empty cells to zero (meaning there was nothing in that category.)\nDrag “Department” to the row area\nDrag the type_case to the filter area\nDrag the “department” to the Values area and make sure it says “Count of Department”.\nDrag the pd_total to the Values area, and make sure it says “Sum of pd_total”. If it doesn’t, change the pivot table calculation to “Sum”. Repeat that three times, with “average”, “min” and “max”.\n\n\n\nOther questions\n\nWhat department had the most claims made against them from FY 2015-16 to through 2019-2020?\nHow much did the city pay in that time because of complaints against Streets. Did any department pay more?\nYour turn: Ask an interesting question of this data and try to answer it.",
    "crumbs": [
      "Spreadsheets",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Practice exercise</span>"
    ]
  },
  {
    "objectID": "appendix-math.html",
    "href": "appendix-math.html",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "",
    "text": "A.1 The PERS: Fractions, rates, percents and per capita\nYou can usually simplify your story if you can re-jigger your numbers into a rate, a ratio or a percentage. “One out of four” is a fraction, or a rate. “Forty percent” is another ratio or rate. And 235 deaths per 100,000 people is another.\nPercents and fractions are used to scale of very large or very small numbers while putting them into perspective.\nRates are also used to level the playing field – they compare two items that have a different base.\nWhen you see a lot of numbers in copy, examine them to see if a simple rate – “one of four” or 25 percent – would simplify your story.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  },
  {
    "objectID": "appendix-math.html#the-pers-fractions-rates-percents-and-per-capita",
    "href": "appendix-math.html#the-pers-fractions-rates-percents-and-per-capita",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "",
    "text": "Fractions and percents\nRepeat this: “Percents are fractions. Fractions are percents.” Remembering this all the time will keep you focused on the key element of percentages: They’re ratios, or rates, expressed as a fraction of 100.\n\nFiguring a percent:\nStep 1: Know your base. Think of the words “out of.” It’s the total of all the groups.\nStep 2: Divide the category you care about by the base.\nRemember that a fraction sign (/) means “divided by” (÷).\nStep 3: Move the decimal point two places to the right (or multiply by 100) to get the rate per hundred, or percent.\nStep 4: Round the answer to no more than one decimal place. Better\nyet, look for an easier fraction your readers will understand.\n\nFormula\nStep 1: Total = The base\nStep 2: (Category / Total) = Proportion\nStep 3: Proportion x 100 = Percent\nStep 4: Round and simplify.\n\nExample\nIf 58 people say they will vote in an upcoming election and 92 say they won’t, this is how to compute the percent of people who claim they will vote:\nStep 1: Base = number of people asked = 92 + 58 = 150\nStep 2: Rate = 58 out of 150 = 58/150 = .386666..\nStep 3: Percent = .38666… x 100 = 38.666666….\nStep 4: Round and simplify: = nearly 40 percent\n\n\n\nFrom fractions to percents and back\n\n\n\nYou probably know that 1 out of 4 is one-quarter, and that it’s also 25 percent. But you may not know how to get from one to another.\nFrom fractions to percents:\n1/4 = 1 ÷ 4 = 0.25. Move the decimal place over two places, or multiply by 100, to get 25%\nFrom percents to fractions:\n\nWrite your percent as a fraction: 25/100\nTry to find a “least common denominator:” 25 in this case goes into both the top and the bottom. You might want to round off either number to come out to a simple denominator.\nSimplify: (25 / 25) / (100 / 25) = 1 / 4\n\nTo get “One out of “ numbers:\n\nExpress your percentage as a proportion by dividing by 100, so 25% is 0.25.\nNow divide one by that number: 1 / .25 = 4, so your answer is one-fourth.\n\nTip for spreadsheet users: Excel allows you to format a number as a fraction or a percent. Play around with formats to see how the number is most easily described.\n\n\n\n\n\nRates and per capita\nAs with percentages, per person or per capita rates are used to level the playing field.\nThey’re often used when you need to compare two dissimilar places or events: Crimes in cities with different populations, deaths from various diseases or Gross Domestic Product across countries.\nRates also are often used with very big or very small numbers to change them into something we can understand.\nSometimes, though, a rate makes things more complicated, especially when events are rare and there is a consensus that they shouldn’t ever happen. Some examples include the 32 crashes attributed to GM’s faulty ignition switch, or the 64 deaths that the Centers for Disease Control associated with pharmacy compounding errors in 2012.\nOne rule of thumb is to use raw numbers when they are under 100, and revert to some kind of fraction or rate when they grow bigger.\n\nRates for large numbers\nA raw per-person figure is an average and should usually be used with very big numbers.\nA Gross Domestic Product of $17 trillion is hard to digest. So we reduce it to a number we can understand. If we divide it by 317 million, we get about $54,000 for every man, woman and child in the country. It doesn’t mean that each person earned $54,000 – in fact, almost half of all families earned less than that altogether at this writing. Instead, it includes all of the income that is generated by companies as well as people.\nBut the device turns an incomprehensible number into something we can picture. It also helps if we want to compare countries – it levels the playing field by adjusting for the size of the country.\n\n\nRates for small numbers - crime, death, and other rare events\nRates such as 23 per 1,000 people or something like it – are the same as percentages, but you multiply by something bigger than 100 or move the decimal place further to the right. Use these for very small numbers.\nIf 2.5 million people die in this country every year, then the percentage of people who die is a really small number: 0.789 per 100, or percent.\nA number that little is hard to digest. So experts up the ante and express the figure as 789 deaths per 100,000 people.\n\n\n\n\n\n\nSmall numbers warning\n\n\n\nBe careful about rates based on very small numbers. One example is the number of police shootings per 100,000 people. Most police departments in the country are very small and are more likely to serve only about 5,000 people. This means that just one shooting in the department can lift them from one of the lowest rates in the nation to one of the highest. Expect rates based on very small numbers to be unstable and potentially misleading.1\n\n\n\nFiguring a rate\nStep 1: Choose your base. This is often difficult. In reporting on fatalities by make of car, should you use the number of cars on the road, the number sold, or the total miles driven each year? You’ll have to decide.\nStep 2: Divide the number you care about by the base. Choosing the numerator can also be tricky. Going back to the automobile fatality example, would you use the total number of deaths or the number of driver deaths? Take a hint using other reports you see on the topic. Experts have often come to an informal agreement about what the most telling number is.\nStep 3: Multiply by a nice round number, such as 1,000, 100,000 or 1 million.\nStep 4: Round the answer and simplify.\n\nFormula\nStep 1: Choose the base, or “total”\nStep 2: (Category / Total) = Proportion or Rate\nStep 3: Proportion x 1,000 = Rate per thousand\nStep 4: Round to zero decimal places\n\nExample\nAccording to the FBI Crime in the United States for 2012, there were 13,000 violent and property crimes in Pittsburgh out of a population of 312,000. There were 8,870 crimes in Tucson out of a population of 531,000. Figuring a rate per thousand residents lets you compare the two cities:\n\n\n\n\n\n\n\nPittsburgh\nTucson\n\n\n\n\nStep 1: Base= 312,000 people\nStep 1: Base = 531,000 people\n\n\nStep 2: 13,000 crimes / 312,000 people = 0.041\nStep 2: 8,870 / 531,000 people = 0.017\n\n\nStep 3: 0.041 x 1,000 = 41 crimes per thousand\nStep 3: .017 * 1,000 = 17 crimes per thousand\n\n\n\nSo the crime rate for Pittsburgh was nearly 2 1/2 times that of Tucson that year , or 47/17 = 2.4\n\n\n\nSelecting your multiplier\n\n\n\nSome people feel that changing their multiplier from 100 to something bigger is cheating.\nAfter all, a 0.2 percent rate becomes a big number – 200 – when you change the base from 100 to 100,000!\nIn practice, though, there’s nothing magical about using a base of 100 (or percent). Instead, use the number that makes sense for the comparison you’re making.\n\nChoose a round number – 1,000, 1 million or 100,000.\nChoose the same number that the experts use: Crimes per 1,000 people, deaths per 100,000, or crashes per million miles driven, for example.\nChoose a base that will give you an easy way to express it to your readers. This is one that results in a number generally between 1 and 1,000 or so.\nTry to avoid using an outrageously large base. For instance, avoid expressing a local number in terms of 1 million people. Only a handful of cities have more than a million people.\nKeep the same base throughout your story. Don’t shift from 100,000 to 1,000 in crime statistics, for instance, when you move from murders to total crime rates.\n\nYou will often have to balance these rules of thumb against each other to come up with a compromise that allows you to write gracefully while keeping the sense of scale appropriate for the comparisons you’re making.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  },
  {
    "objectID": "appendix-math.html#measuring-change",
    "href": "appendix-math.html#measuring-change",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "A.2 Measuring change",
    "text": "A.2 Measuring change\nWe often write about change or difference, usually as a difference between place or time.\n\nSimple differences\nA simple difference is just the result of subtracting one number from another. If you are measuring differences in time, it’s the newer number minus the older number.\nOne time to use a simple difference is when the number is understandable without any calculations. Prices of common household goods, salaries and home prices are examples of numbers that needn’t always be put into perspective using percentage changes.\nIn the end, we work in news. That means that sometimes you’ll use a raw number when it’s more newsworthy. This doesn’t necessarily mean the number is more alarming – just more meaningful.\n\nFiguring a difference:\nSubtract the older number from the newer number.\nThis is not the same as subtracting the little number from the big number.\nIf a number has fallen you get a negative number. If a number has risen you get a positive number.\nFormula\nNew – Old.\nExample An executive made $2.4 million last year. She made $2.9 million this year.\nHer raise was: $2.9 – $2.4 = 0.5 million, or $500,000, or half a million dollars.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  },
  {
    "objectID": "appendix-math.html#percent-change-percent-difference",
    "href": "appendix-math.html#percent-change-percent-difference",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "A.3 Percent change / Percent difference",
    "text": "A.3 Percent change / Percent difference\nThe most butchered form of newsroom math is the percent difference, or the percent change.\nPart of the problem is that some folks have found five or six different ways to compute them. Unfortunately, only two of them work every time. I’ll show you both because sometimes – especially when you want to compare rates – one is easier than the other.\nNote that these methods work whether or not the number is going up or going down. If the number has fallen, you’ll get a negative answer. If the number has risen, you’ll get a positive one. And it still comes out right if the increase is bigger than 100 percent.2\nIn practice, I use Method 1 when I’m working in spreadsheets because I can look at the simple difference in one column and then use it in the formula for the percentage difference. I use Method 2 when I want to compare to percent changes to one another or when working with annual rates.\n\n\n\n\n Method 1: Subtract then divide\n\n\n\n Method 2: Divide then subtract\n\n\n\n\n\n\n\nFiguring a percent change\n\n\n\n\n Step 1: Get the simple difference between the numbers by subtracting the older number from the newer number. It doesn’t matter which one is bigger!\nStep 2: Divide the answer by the older number.\nStep 3: Multiply by 100, or move the decimal point two places to the right.\nStep 4: Round off and simplify.\n\n\n\n Step 1: Get the proportion of the new number compared to the old number. This is the same as the percent of total above, except the old number is the base.\nStep 2: Subtract 1 from that ratio\nStep 3: Multiply by 100, or move the decimal point two places to the right.\nStep 4: Round off and simplify.\n\n\n\n\n\n\n\n\n\nFormula\n\n\n\n\n Step 1: New – Old = Difference\nStep 2: Difference / Old = Decimal answer\nStep 3: Decimal x 100 = percentage difference\nStep 4: Round off.\n\n\n\n Step 1: New / Old = Ratio\nStep 2: Ratio - 1 = Decimal answer\nStep 3: Decimal x 100 = percentage difference\nStep 4: Round off.\n\n\n\n\n\n\n\n\nExample\n\nAn executive made $2.4 million last year. They made $2.9 million in this year.\n\n\nStep 1: Difference = 2.9 – 2.4 = 0.5\nStep 2: Difference / Original number =  0.5 / 2.4 = .208\nStep 3: Move the decimal point = 20.8%\nStep 4: Round off and simplify:  21% = 21 / 100 = about 20 / 100 = or about one-fifth.\n\n\n\nStep 1: Ratio = 2.9/2.4 = 1.208\nStep 2: Decimal answer = 1.208 - 1 = .208\nStep 3: Move the decimal point = 20.8%\nStep 4: Round off and simplify:  21% = 21 / 100 = about 20 / 100 = or about one-fifth.\n\n\nSo the executive got a raise equivalent to one-fifth of their original salary.\n\n\n\n\n\n\n\n\nReversing or predicting a percent change\n\n\n\nRemember that a number can grow many times, but it can only fall 100 percent to zero. This is a rough concept until you think it through. If you double a price of $20, increasing it by 100%, it’s $40. If you triple it, it’s $60. But if you reduce the $40 back to $20, it’s a 50 percent drop, to one-half the level, not a 100 percent decrease. In other words, percent changes can’t be reversed.\nThis means that the ads claiming you’ll use three times less detergent or a food contains three times less salt are wrong and impossible. What they probably mean is that it would be three times as much if you used the other brand or ate the other food, or the brand is one third as much. Here are two ways this makes a difference:\nYou need two of three numbers to reverse or predict a percent change:\n\nWhere the number started\nWhere it ended\nWhat the percent change would (or will) be\n\nAny two of those will give you what you need. It’s easiest if we use Method 2 above to get there. The example above assumes you know where it started and where it ended. Here’s how to do it if you you have either of the other two:\nWhere it starts and the percent change\nExample: You started with $100 and it grew by a total of 12%. Or, you started with $100 and it fell by a total of 12% (the percent change was -12%)\nStep 1: Convert the percent change to a ratio by moving the decimal place back : .12 (up) or -.12 (down)\nStep 2: Add 1, resulting in 1.12 (up) or .88 (down)\nStep 3: Multiply the beginning number by that amount : $100 x 1.12 = $112 (up), or $100 x .88 = $88 (down)\nWhere it ends and the total percent change\nFor example, say your house is worth $330,000, and it had appreciated by a total of 15% over the past few years. Here’s how to figure out where it started:\nStep 1: Convert the percent change to a decimal, as above: 0.15\nStep 2: Divide the current value by that amount = $330 / .15 = $287\nThis isn’t intuitive, but it differs because you’re starting from a bigger base. 15 percent of 330 isn’t the same as 15 percent of 287.\n\n\n\n\n\n\n\nGoing further with percents and rates\nThere are three common problems in changes and rates you will probably encounter that aren’t part of this guide. You should get help or look it up when these situations come up: 3\n\nRelative risk: That’s the technical term for dividing two percentages. If the mortgage denial rate for Black homeowners was 10 percent, and the denial rate of white homeowners was 5 percent, it means that Black homeowners are twice as likely to be denied a loan. This can be used with both rates and with changes.\nAnnual rates: When you know that something has grown, say, 2 percent a year for 10 years, it’s not the same thing as 20 percent. You have to annualize it.\nAdjusting for inflation: Comparing values across two points in time – especially today – means putting them on the same footing. Generally, you want to convert old values to their buying power today. For example, it’s hard to compare salaries for teachers today with those 50 years ago, because our money isn’t worth as much today.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  },
  {
    "objectID": "appendix-math.html#average-and-typical-values",
    "href": "appendix-math.html#average-and-typical-values",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "A.4 Average and typical values",
    "text": "A.4 Average and typical values\nAverages4 are just summaries. If a quote sums up an event, or an anecdote sums up a person using their actions instead of words, an average sums up a human condition of some kind – money, congestion, death or disease – in a single number.\nChoosing your average carefully or deciding there may be another number or method to sum up a situation can mean the difference between accurately and inaccurately describing your story.\nUnderstanding different kinds of “measures of central tendency” – what they tell us and what they don’t – is the first thing you learn in basic statistics classes. If an it doesn’t describe your data well, it’s not very productive to move forward into many other kinds of analysis.\nTrying to compare populations over time is particularly tricky using averages because of giant demographic shifts. Between the Baby Boom and the Millennials came what some people call the Baby Bust. Getting average spending on education, for example, across these generations is really misleading – it will boom, then bust, them boom again and no one number will describe that pattern.5\nTwo types of averages are reviewed here. Consult an introductory statistics book if your work depends on an average.\n\nThe average or mean\nA “mean” is what people mean when they say the word “average”.\nIt’s most descriptive when it summarizes numbers that don’t vary too much at either the top or bottom ends. These averages will often be misleading when they refer to items measured in dollar amount like incomes, housing costs and the like.\n\nFiguring a simple average or mean\nStep 1: Add up a list of numbers.\nStep 2: Divide the answer by the number of numbers you’ve added up.\nFormula\nStep 1: Sum of numbers\nStep 2: Sum / Count of numbers\nFor spreadsheet users: =AVERAGE(list of numbers)\nExample\nHere are six home prices on a block:\n$275,000          $1,200,000\n$275,000            $500,000\n$200,000            $395,000\n\nStep 1: 275 + 275 + 200 + 1,200 + 500 + 395 = 2,845 or $2,845,000\nStep 2: $2,845,000 / 5 = $569,000.\nSo the average home price is more than all but one on the list.\n\n\n\nThe median\nMedians are often used to summarize the value of things measured in dollars, especially home prices and incomes. They are not sensitive to one or two unusually high or low values the way the average in the previous example is.\nBut it’s harder to get a median because you need a list of all values. For example, if you know the total income of a metropolitan area and the number of people in that area, you can compute the average – or per capita income – but not the median.\nOne way to express the median is to call it the “typical” value. Another way is to say that it’s the “middle” value.\n\nFiguring a median:\nStep 1: List all of your numbers in order, beginning with the lowest and ending with the highest.\nStep 2: Count how many numbers you have and divide by two.\nStep 3: Add 0.5. If that comes out to a whole number (like 13), count up the list that many values.\nIf it’s not (like 12.5), take the average of the two numbers surrounding the number. 6\nIn other words, this is the closest you can get to the middle of the list. This is a sorting and counting job, not a calculator job.\nIn a spreadsheet, use the =MEDIAN() function.\nExample:\nStep 1:\nThe same list, but listed from lowest to highest, with an extra expensive home\n1.    $200,000\n2.    $275,000      \n3.    $275,000      \n4.    $395,000\n5.    $500,000\n6.  $1,200,000\nStep 2: 6/2 = 3\nStep 3: 3 + .5 = 3.5\nStep 4: Average the 3rd and 4th items on the list: (275 + 395) / 2 = $335,000\n\nAs a rule of thumb, the median will be more telling than the average when they’re very different as in this example. But the word “median” sounds very technical to some readers and the average encompasses all of the values in a list, so we use it when they’re not too different.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  },
  {
    "objectID": "appendix-math.html#footnotes",
    "href": "appendix-math.html#footnotes",
    "title": "Appendix A — Newsroom numbers cheat sheet",
    "section": "",
    "text": "Note the disclaimer in this story on police shootings by The Washington Post, in which changes in the rates of police shootings may just be random.↩︎\nIt’s impossible for a number to fall more than 100 percent. That would mean it went below zero and then no formula works. There’s no good way to show a percent change when a figure like annual company earnings goes from profit to loss.↩︎\nThey are part of the “Numbers in the Newsroom” book from which this guide is derived.↩︎\nI’m using the term “average” freely here. Technically, a simple average and median are measures of central tendency, but I’ll treat them as different types of averages for simplicity sake.↩︎\nThis is sort of an example of “Simpson’s paradox” in that an average hides meaningful trends among sub-populations.↩︎\nIn statistical programs like R, there are various ways to specify how to deal with medians when there are ties like this. This is the most common way, but it may not be the way your program handles it.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Newsroom numbers cheat sheet</span>"
    ]
  }
]